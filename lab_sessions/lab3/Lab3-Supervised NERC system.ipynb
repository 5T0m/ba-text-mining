{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3-Supervised NERC classifier (SVM)\n",
    "\n",
    "In this notebook, we provide more information about Named Entity Recognition and Classification (NERC).\n",
    "\n",
    "**At the end of this notebook, you will be able to**:\n",
    "* understand the IOB format used to format NERC data\n",
    "* represent linguistic features as vectors\n",
    "* train a NERC classifier (SVM)\n",
    "* apply the classifier to unseen data\n",
    "\n",
    "**Useful links**:\n",
    "* [blog about SVM](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47)\n",
    "* [blog about SVM in scikit-learn](https://medium.com/@aneesha/visualising-top-features-in-linear-svm-with-scikit-learn-and-matplotlib-3454ab18a14d)\n",
    "* [blog about inspecting top features using scikit-learn](https://towardsdatascience.com/named-entity-recognition-and-classification-with-scikit-learn-f05372f07ba2)\n",
    "* [one hot encoding](https://scikit-learn.org/dev/modules/feature_extraction.html#loading-features-from-dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NERC\n",
    "In Named Entity Recognition and Classification, the goal is to determine which noun phrases refer to named entities as well as classifying them.\n",
    "Named entities can be persons, locations, organizations, etc. (see [NLTK Chapter 7, Section 5](https://www.nltk.org/book/ch07.html) for more information on the task)\n",
    "\n",
    "![title](https://researchkb.files.wordpress.com/2014/02/ner.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not trivial to represent NERC data in a way that we can easily train NLP systems as well as evaluate them. One of the most used formats is called [Inside–outside–beginning (IOB)](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)). Let's look at an example from one of the most popular datasets, which is [CoNLL-2003](http://aclweb.org/anthology/W03-0419).\n",
    "```\n",
    "Germany NNP B-NP B-LOC\n",
    "'s POS B-NP O\n",
    "representative NN I-NP O\n",
    "to TO B-PP O\n",
    "the DT B-NP O\n",
    "European NNP I-NP B-ORG\n",
    "Union NNP I-NP I-ORG\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first observation is that all information is represented at the **token-level**. For each token, e.g., *Germany*, we receive information about:\n",
    "* **the word**: e.g., *Germany*\n",
    "* **the part of speech**: e.g., *NNP* (from [Penn Treebank](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html))\n",
    "* **the phrase type**: e.g., a noun phrase\n",
    "* **the NERC label**: e.g., a location (LOC).\n",
    "\n",
    "This example contains two named entities: *Germany* and *European Union*.\n",
    "\n",
    "Every first token of a named entity is prefixed with *B-*. Every token after that, e.g., *Union* in *European Union*, is prefixed with *I-*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the IOB format is at the **token-level**, which means that we also are going to train and evaluate an NLP system at the token-level! The goal will hence not be to classify *European Union* as an *Organization*, but to classify:\n",
    "* *European* as the first token of an entity that is an *Organization*\n",
    "* *Union* as a token inside of an entity that is an *Organization*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVM\n",
    "We are going to train an SVM for the NERC task. The goal of an SVM is to find a hyperplane in an n-dimensional space that distinctly classifies the data points. This is exactly the problem at hand. We have multiple NERC labels and we want to classify them correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Scikit-learn\n",
    "We are going to use the **svm** module from **sklearn**, from which we will select the **LinearSVR** (Linear Support Vector Regression) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.svm.classes.LinearSVR"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.LinearSVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Representing features in sklearn.svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to when we trained a Sentiment Analyzer in Lab 2, we need to represent training instances using a vector representation. For each training instance, we need:\n",
    "* **its feature vector** (the representation of some input)\n",
    "* **the NERC label** (the corresponding output class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show how to train and evaluate an SVM using a made-up example of multi-class classification for a non-linguistic dataset. The goal is to predict someone's weight category (say: skinny, fit, average, overweight) based on their properties.\n",
    "\n",
    "We use three features:\n",
    "* **age in years**\n",
    "* **height in cms**\n",
    "* **number of ice cream cones eaten per year**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature representation is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[30, 180, 1000], \n",
    "     [80, 180, 100],\n",
    "     [50, 180, 100],\n",
    "     [40, 160, 500],\n",
    "     [15, 160, 400]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that each row represents a training instance, i.e., the age, height, and the number of ice cream cones eaten in a year for a specific person. Each column represents a feature, i.e., the first column represents the age feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are represented in the following way, i.e., the correct weight categories of each training instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [\"overweight\", \n",
    "     \"skinny\",\n",
    "     \"fit\",\n",
    "     \"average\",\n",
    "     \"average\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Training and testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instanciate the model that we'll be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_clf = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model. You might get a warning stating that:\n",
    "```\n",
    "ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to be expected given that we only train using five instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now **apply the model to new instances**: what does it think the weight category is of someone of 18 years, 171cm, and who eats a 350 ice cream cones per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['average']\n"
     ]
    }
   ],
   "source": [
    "predicted_label = lin_clf.predict([[18, \n",
    "                                    171, \n",
    "                                    350]])\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently the SVM thinks it is **average**, which is not surprising since **number of ice cream cones eaten per year** and **height** seem to correlate highly with the weight categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Incorporating linguistic features: one-hot encoding\n",
    "\n",
    "So far, we dealt with features that were numbers. However, in NLP problems, we often deal with features such as:\n",
    "* part of speech\n",
    "* lemma\n",
    "* ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can an SVM deal with strings? The answer is: not really.\n",
    "How can we then represent linguistic information about each token in the following phrase:\n",
    "* **... Germany's representative to the European Union ...**\n",
    "\n",
    "In the IOB-format, the phrase has the following representation:\n",
    "\n",
    "```\n",
    "Germany NNP B-NP B-LOC\n",
    "'s POS B-NP O\n",
    "representative NN I-NP O\n",
    "to TO B-PP O\n",
    "the DT B-NP O\n",
    "European NNP I-NP B-ORG\n",
    "Union NNP I-NP I-ORG\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can if we use something called **one hot encoding**! When we represented *age* in the example from above, we used one column for that feature (see the first column of the matrix `X` above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Generating features per instance (e.g., token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one hot encoding, you use a column for **each possible value** of a feature. This means that it is important to know the possible values of a feature since this will be a closed class. We represent for each feature value whether the feature in that value occurs in a training instance. \n",
    "We will now try to represent the features **part of speech** and **lemma**.\n",
    "\n",
    "Let's first generate those values for each of our tokens, with SpaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp=spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Germany's representative to the European Union\"\n",
    "doc=nlp(text)\n",
    "\n",
    "training_instances=[]\n",
    "for token in doc:\n",
    "    one_training_instance={'part-of-speech': token.pos_, 'lemma': token.lemma_}\n",
    "    training_instances.append(one_training_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'part-of-speech': 'PROPN', 'lemma': 'Germany'},\n",
       " {'part-of-speech': 'PART', 'lemma': \"'s\"},\n",
       " {'part-of-speech': 'NOUN', 'lemma': 'representative'},\n",
       " {'part-of-speech': 'ADP', 'lemma': 'to'},\n",
       " {'part-of-speech': 'DET', 'lemma': 'the'},\n",
       " {'part-of-speech': 'PROPN', 'lemma': 'European'},\n",
       " {'part-of-speech': 'PROPN', 'lemma': 'Union'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our instance information is now a list with dictionaries, with each dictionary representing a training instance (token) with two values (POS tag and lemma).\n",
    "We can now try to convert these values to a numeric vector representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Vectorizing our features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accomplish this, we use the **DictVectorizer** from sklearn ([link to documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) ). \n",
    "\n",
    "Please recall that in lab session 2 we used two other vectorizers, that create bag-of-words or tf-idf vectors from a vocabulary of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = DictVectorizer()\n",
    "\n",
    "the_array = vec.fit_transform(training_instances).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Analyzing the vectorized format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now print the resulting vector representation. Each row represents the features for one token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(the_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the third column now informs us whether a training instances contains the feature *lemma* with the value *Germany*. If this is not the case, the value is 0. If this is the case, the value is 1. Please note that the number of columns grows immmensely when using one hot encoding (you can easily play with this by changing the input sentence above).\n",
    "\n",
    "\n",
    "Generally speaking, each column represents a **specific value** of a lemma or POS tag. We can get more information on this from the vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"lemma='s\", 'lemma=European', 'lemma=Germany', 'lemma=Union', 'lemma=representative', 'lemma=the', 'lemma=to', 'part-of-speech=ADP', 'part-of-speech=DET', 'part-of-speech=NOUN', 'part-of-speech=PART', 'part-of-speech=PROPN']\n"
     ]
    }
   ],
   "source": [
    "print(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the second column for example stands for the lemma 'European'. Most words do not have this lemma, but the second last word has it. For that reason, we can see that the second column in the second last row has a value 1.\n",
    "\n",
    "Similarly, the last column represents the tokens with a PROPN (proper noun) part-of-speech. We can see that three words have this part-of-speech tag, namely the words represented in the rows: 1, 6 and 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As a final analysis step, let's inspect the first row, i.e. the one hot encoding representation of the following training instance,\n",
    "```\n",
    "{'part-of-speech': 'PROPN', 'lemma': 'Germany'}\n",
    "```\n",
    "The feature vector using one hot encoding is:\n",
    "```\n",
    "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    "````\n",
    "* **first value: 0**: the feature *lemma* with the value *'s* does not occur in the training instance\n",
    "* **second value: 0**: the feature *lemma* with the value *European* does not occur in the training instance\n",
    "* **third value: 1**: the feature *lemma* with the value *Germany* does occur in the training instance\n",
    "* ...\n",
    "* **last value: 1**: the feature *part-of-speech* with the value *PROPN* does occur in the training instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Training an SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you can see the resemblance of the vectors here to the ones we generated with bag-of-words and tf-idf last week. Not surprisingly, we can now train and test a machine learning model, such as SVM. Given that our model is trained on only 7 input vectors, it will not be a meaningful one yet; we will build a model with sufficient data in the assignment.\n",
    "\n",
    "To train, we also need to have the 'gold' labels for each of the token. Let's define them manually here, according to the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=['B-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(the_array, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Testing our model on new examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now reuse the same vectorizer of the training data to vectorize any new example we want to train, and perform prediction on it using the trained SVM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "new_training_instances={'lemma': 'America', 'part-of-speech': 'PROPN'}\n",
    "vectorized=vec.transform(new_training_instances)\n",
    "print(vectorized.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-ORG'], dtype='<U5')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=lin_clf.predict(vectorized)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embeddings-based NERC model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Quick introduction to embeddings\n",
    "\n",
    "Extracting features manually can get us a long way. In addition to lemma and part-of-speech, people have used a huge number of other information: previous words (on the left), next words (on the right), whether the word starts with a capital, whether it is an abbreviation, etc.\n",
    "\n",
    "One recent way to create a 'semantic' representation of a word is by word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will load pre-trained word embeddings called word2vec, created by Google. \n",
    "\n",
    "First, please download the file from [their google drive](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit). Create a folder in the same directory as this notebook, called 'model' and unpack the word2vec file in that folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the file using the gensim library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings are expected to capture certain meaning of the words. Previous research has shown to some extent that they are good in terms of simiarity, relatedness, and analogy. For example, we can compute the cosine similarity between two word vectors. We will expect for example, that cat and tiger is more similar than cat and Germany. Feel free to play a bit with the words below to get some feeling of the information these embeddings capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6477412]]\n"
     ]
    }
   ],
   "source": [
    "word1='tapas'\n",
    "word2='pintxos'\n",
    "dog_vector=np.array(model[word1]).reshape(1, -1)\n",
    "cat_vector=np.array(model[word2]).reshape(1, -1)\n",
    "print(cosine_similarity(dog_vector, cat_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the most similar words to some word, say 'apple':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apples', 0.720359742641449), ('pear', 0.6450697183609009), ('fruit', 0.641014575958252), ('berry', 0.6302294135093689), ('pears', 0.6133961081504822), ('strawberry', 0.6058261394500732), ('peach', 0.6025872230529785), ('potato', 0.5960935354232788), ('grape', 0.5935864448547363), ('blueberry', 0.5866668224334717)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar('apple', topn=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Using embeddings in our NERC model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now replace our one-hot input representation of our words with embeddings. We will do that by simply looking up each word in the embeddings model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no fun 's\n",
      "no fun to\n"
     ]
    }
   ],
   "source": [
    "training_inputs=[]\n",
    "for token in doc:\n",
    "    word=token.text\n",
    "    if word in model:\n",
    "        vector=model[word]\n",
    "    else:\n",
    "        vector=[0]*300\n",
    "        print('no fun', word)\n",
    "    training_inputs.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(training_inputs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the model** Let's say we want to test our model with the sentence: 'I love beer from Munich'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence='I love beer from Munich'\n",
    "test_doc=nlp(test_sentence)\n",
    "gold_labels=['O', 'O', 'O', 'O', 'B-LOC']\n",
    "\n",
    "test_inputs=[]\n",
    "\n",
    "for token in test_doc:\n",
    "    word=token.text\n",
    "    if word in model:\n",
    "        vector=model[word]\n",
    "    else:\n",
    "        vector=[0]*300\n",
    "    test_inputs.append(vector)\n",
    "    \n",
    "pred=lin_clf.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'O', 'O', 'O', 'B-LOC'], dtype='<U5')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. NERC datasets\n",
    "\n",
    "### 5.1 CoNLL-2003\n",
    "\n",
    "Now that we've seen how to represent linguistic features, we also need to access relevant linguistic training data for the NERC task. One of the most popular datasets is [CoNLL-2003](http://aclweb.org/anthology/W03-0419), which was provided with the zip file you downloaded from Canvas.\n",
    "You can load it using the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU NNP B-ORG\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "\n",
    "train = ConllCorpusReader('NERC_datasets/CONLL2003', # the folder where ConLL-2003 is stored (you downloaded this with the zip file from canvas) \n",
    "                          'train.txt', # this will load the file 'train.txt', for the exercise you also need to load 'test.xt' \n",
    "                          ['words', 'pos', 'ignore', 'chunk'])\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "    print(token, pos, ne_label) # please represent this information using a dictionary for the feature representation\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can for example iterate through this data, and make a list of the tokens as inputs, and of the `ne_label` values as desirable outputs. The input tokens could for example be looked up in our word embeddings dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors=[]\n",
    "labels=[]\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "    \n",
    "    if token!='' and token!='DOCSTART':\n",
    "        if token in model:\n",
    "            vector=model[token]\n",
    "        else:\n",
    "            vector=[0]*300\n",
    "        input_vectors.append(vector)\n",
    "        labels.append(ne_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully loaded our data. Let's see how many tokens/labels we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203621\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step, we could easily train a model on this data as shown in section 4.2 above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Kaggle\n",
    "Another interesting dataset is the [Annotated Corpus for Named Entity Recognition](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus), which we also provided in the zip file you downloaded from Canvas. You can load it in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'NERC_datasets/kaggle/ner_v2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
     ]
    }
   ],
   "source": [
    "kaggle_dataset = pandas.read_csv(path, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see the following output after running the above code cell:\n",
    "```\n",
    "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n",
    "```\n",
    "You can ignore this.\n",
    "\n",
    "**pandas.read_csv** will load the csv file into a [pandas DataFrame](https://towardsdatascience.com/pandas-dataframe-a-lightweight-intro-680e3a212b96)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect which columns are in the csv file by running the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'lemma', 'next-lemma', 'next-next-lemma', 'next-next-pos',\n",
       "       'next-next-shape', 'next-next-word', 'next-pos', 'next-shape',\n",
       "       'next-word', 'pos', 'prev-iob', 'prev-lemma', 'prev-pos',\n",
       "       'prev-prev-iob', 'prev-prev-lemma', 'prev-prev-pos', 'prev-prev-shape',\n",
       "       'prev-prev-word', 'prev-shape', 'prev-word', 'sentence_idx', 'shape',\n",
       "       'word', 'tag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Here](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus), you can read what each column represents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You loop can loop through the dataset in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "id                             0\n",
      "lemma                   thousand\n",
      "next-lemma                    of\n",
      "next-next-lemma         demonstr\n",
      "next-next-pos                NNS\n",
      "next-next-shape        lowercase\n",
      "next-next-word     demonstrators\n",
      "next-pos                      IN\n",
      "next-shape             lowercase\n",
      "next-word                     of\n",
      "pos                          NNS\n",
      "prev-iob              __START1__\n",
      "prev-lemma            __start1__\n",
      "prev-pos              __START1__\n",
      "prev-prev-iob         __START2__\n",
      "prev-prev-lemma       __start2__\n",
      "prev-prev-pos         __START2__\n",
      "prev-prev-shape         wildcard\n",
      "prev-prev-word        __START2__\n",
      "prev-shape              wildcard\n",
      "prev-word             __START1__\n",
      "sentence_idx                   1\n",
      "shape                capitalized\n",
      "word                   Thousands\n",
      "tag                            O\n",
      "Name: 0, dtype: object\n",
      "NERC label O\n"
     ]
    }
   ],
   "source": [
    "for index, instance in kaggle_dataset.iterrows():\n",
    "    print()\n",
    "    print(index)\n",
    "    print(instance) # you can access information by using instance['A COLUMN NAME'] which you can use to convert to a dictionary needed for the feature representation.\n",
    "    print('NERC label', instance['tag'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could for instance use these features as inputs in a machine learning model with our DictVectorizer, or by transforming them using embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
