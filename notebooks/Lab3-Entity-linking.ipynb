{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB3 - Entity Linking/Named Entity Disambiguation\n",
    "\n",
    "In this notebook we will learn about the task of Named entity linking/disambiguation. We will cover the following aspects:\n",
    "1. Task definition\n",
    "2. Opportunities and challenges\n",
    "3. The three components of every Entity linking system\n",
    "4. Evaluating entity linking\n",
    "5. Code example for evaluating entity linking\n",
    "6. Performing disambiguation with existing tools\n",
    "7. Entity disambiguation from scratch: recognition and disambiguation together\n",
    "\n",
    "### 1. Task definition\n",
    "\n",
    "**Entity tasks so far** So far, we have seen two tasks that relate to the entities mentioned in text: \n",
    "1. recognizing/spotting entity mentions in text in the task of *Named Entity Recognition*\n",
    "2. classifying these entity mentions to their *type* (for example, Person or City) - this is done in the task of *Named Entity Classification/Typing*\n",
    "\n",
    "**NED** Here, we will introduce Named Entity Disambiguation - NED, also called (Named) Entity Linking - (N)EL. NED is a central task in information extraction. The goal is to take the entity mentions that were found in text with the task of NER and \"disambiguate\" them. In this sense, the task of Entity Disambiguation builds on top of the output of the NER task. Sometimes the tasks are combined together in a task called Named Entity Recognition and Disambiguation (NERD).\n",
    "\n",
    "**Disambiguation** Ok, so WHY do we need to disambiguate entity mentions found in text and HOW do we do that?\n",
    "\n",
    "*WHY*: Let's take an entity mention we find in text, like \"JFK\". This phrase can mean different things. It can refer to John F. Kennedy (the former American president), or the airport in NYC with the same name , or to \"Justice For Khojaly\", etc. So, with this disambiguation we want to say precisely which of these world entities is the correct one in a specific textual document.\n",
    "\n",
    "*HOW*: To disambiguate, we need a way to map this ambiguous mention found in text to a unique \"representation\" that already exists which has a clear meaning. Such representations, for example, are the Wikipedia pages of these world entities, because each Wikipedia page has a URL (\"http:///wikipedia.org/...\") and each URL describes exactly one entity. For example, https://en.wikipedia.org/wiki/John_F._Kennedy_International_Airport  describes the JFK airport and not the president.\n",
    "\n",
    "Resources like Wikipedia are called *Knowledge Bases (KBs)*, because they contain knowledge about entities in the world. There are two types of knowledge bases: structured and unstructured. Named Entity Disambiguation in practice is sometimes performed with respect to unstructured and sometimes with respect to structured KBs.\n",
    "\n",
    "Wikipedia is an example for an unstructured knowledge base, because most of its content is in unstructured (running text) form, such as: \"John F. Kennedy international airport is a public airport owned by the city of New York ...\" \n",
    "\n",
    "Examples for structured knowledge bases are DBpedia and Wikidata. In a structured knowledge base, we would not have textual description, but rather a structured list of facts, such as:\n",
    "\n",
    "John F. Kennedy International airport\n",
    "```\n",
    "* airport type: public\n",
    "* owner: city of New York\n",
    "* ...\n",
    "```\n",
    "\n",
    "Here is the representation of the JFK airport in these structured knowledge bases:\n",
    "* http://dbpedia.org/resource/John_F._Kennedy_International_Airport\n",
    "* https://www.wikidata.org/wiki/Q8685\n",
    "\n",
    "\n",
    "Note that most entities have information in these three knowledge bases (Wikipedia, DBpedia, and Wikidata). For example, we can find informatiom about the John F. Kennedy airport in Wikipedia (https://en.wikipedia.org/wiki/John_F._Kennedy_International_Airport) or in DBpedia (http://dbpedia.org/resource/John_F._Kennedy_International_Airport). Actually, it is always the case the last part of the URL is the same between Wikipedia and DBpedia (\"John_F.\\_Kennedy\\_International_Airport\" in this case), which is really convenient for us to use information from both places if we want.\n",
    "\n",
    "To summarize, we perform disambiguation of entity mentions in text by connecting them to existing entities in a knowledge base, like Wikipedia. This kind of disambiguation \"links\" the textual mention to an existing representation - for this reason the task is also called Entity Linking.\n",
    "\n",
    "**Example** For example, let's consider the following sentence:\n",
    "\n",
    "\"_JetBlue_ begins direct service between _Barnstable Airport_ and _JFK_.\"\n",
    "\n",
    "The entity mentions we find here are: \"JetBlue\", \"Barnstable Airport\" and \"JFK\". Let's say that we perform linking to DBpedia. Then, “JetBlue” should be linked to the entity http://dbpedia.org/resource/JetBlue, and “JFK” to http://dbpedia.org/resource/John_F._Kennedy_International_Airport. \n",
    "\n",
    "However, there is no entry in DBpedia for the Barnstable Municipal Airport, which is the meaning of the mention “Barnstable Airport”. We cannot link this entity then. The entities for which there is no representation in a chosen knowledge base are called *NIL entities*. When a system processes the text, it should simply say that the meaning of “Barnstable Airport” is _NIL_.\n",
    "\n",
    "### 2. Opportunities and challenges\n",
    "\n",
    "**Connecting text and knowledge bases** This is the first time we encounter such a connection between the information in text and the knowledge bases in the external world in this course. Note that these knowledge bases were not created to improve the text processing. Instead, they exist independently in order to provide knowledge about the world - for example, Wikipedia, DBpedia, and Wikidata give us encyclopedic knowledge. \n",
    "\n",
    "**Opportunities** By creating a link between a phrase in text and a unique entry in a knowledge base, we directly get access to much more knowledge that we can use to enhance the information in text. If we know that 'JFK' refers to the airport, we allow our tools to have access to all facts about this airport, such as its location and founding year. In addition, if we want, we can now extract facts from text and store them in these knowledge bases, but this is another task for later :)\n",
    "\n",
    "**Challenges** So, why is entity linking not an easy task? This relates to two aspects: ambiguity and variance. \n",
    "\n",
    "*Ambiguity* is the amount of meanings that a certain entity mention can have. For example, imagine how many people in the world are called \"John Smith\". DBpedia contains entries for a few hundreds of them, see http://dbpedia.org/page/John_Smith. How can we teach a computer to decide which of these is the one mentioned in text? And, what if the John Smith mentioned in text is a NIL entity and is not stored in DBpedia?\n",
    "\n",
    "There are also many cases where it is quite easy to link an entity to a knowledge base. Often the mentions in text have a small ambiguity (for example, \"Barack Obama\"). Or, they have multiple meanings but one of them is used almost always: for example, there are multiple cities called \"Paris\", but the French capital will be most often mentioned in text.\n",
    "\n",
    "*Variance* is the amount of different mentions that refer to the same entity. For example, http://dbpedia.org/resource/John_F._Kennedy_International_Airport can be called \"JFK\", or \"John F. Kennedy Airport\", or \"The NYC airport\" in text.\n",
    "\n",
    "### 3. Named Entity Disambiguation in practice: 3 phases\n",
    "\n",
    "In practice, most NED systems consist of three phases:\n",
    "\n",
    "1. **Entity recognition/spotting** - this is done as described in the NER(C) task. In the example sentence \"_JetBlue_ begins direct service between _Barnstable Airport_ and _JFK_.\", the recognition phase will detect the entity mentions: \"JetBlue\", \"Barnstable Airport\", and \"JFK\".\n",
    "2. **Candidate generation** - here we take each of the recognized mentions and look up in the knowledge base for potential meanings. For example, the phrase \"JFK\" could have these candidates:\n",
    "    * http://dbpedia.org/resource/John_F._Kennedy\n",
    "    * http://dbpedia.org/resource/John_F._Kennedy_International_Airport\n",
    "    * http://dbpedia.org/resource/JFK_(film)\n",
    "    * http://dbpedia.org/resource/JFK_University\n",
    "    * http://dbpedia.org/resource/Justice_for_Khojaly\n",
    "    \n",
    "   and so on. Similar lists will be generated for the other mentions found in text: \"JetBlue\" and \"Barnstable Airport\". The candidate generation phase is not trivial because of the ambiguity and variation described above. Also, new entities are appearing all the time in news articles, so the number of options grows over time.\n",
    "   \n",
    "To understand the complexity of this step, think about the \"candidate\" classes in sentiment analysis. There, for each case we had to perform classification to one of the same three categories (positive, neutral, negative), while in enitty linking the number of classes is different for each mention and can sometimes be very large.\n",
    "\n",
    "3. **Disambiguation** - the goal of this final phase is to take the list of potential meanings generated in the candidate generation phase for each of the mentions and make a decision on which instance is the correct one. This decision can either be: choosing one of the possible candidates, or deciding that no candidate is the correct one (NIL entity).\n",
    "\n",
    "As the list of candidates is different for each mention, it is not easy to perform this disambiguation with supervised learning approaches as in other tasks (e.g., NER). In practice, most systems use different methods; we will briefly describe two such methods in part 6 below.\n",
    "\n",
    "### 4. Evaluating entity linking\n",
    "\n",
    "**Metric** The correctness of an entity linking system is measured in terms of precision, recall, and F1-score. For each of the mentions in text, we compare the system decision against the gold data:\n",
    "* If the system chose entity X and the gold entity is also X, then we count a *true positive (TP)*\n",
    "* If the system chose entity X, but the gold entity is Y, then we count a *false positive (FP)* and a *false negative (FN)*\n",
    "* If the system opted for a NIL entity and the gold entity is X, then we count a *false negative (FN)*\n",
    "* If the system opted for an entity X but the gold entity is NIL, then we count a *false positive (FP)*\n",
    "\n",
    "Afterwards, we use these numbers for TP, FP, and FN, to compute precision, recall, and F1-score:\n",
    "\n",
    "* `precision=TP/(TP+FP)` -> From the decisions made by the system, how many were true\n",
    "* `recall=TP/(TP+FN)` -> From the gold entities, how many were found correctly by the system\n",
    "* `f1=2*precision*recall/(precision+recall)` -> compute a harmonic mean between precision and recall, called F1-score\n",
    "\n",
    "Note that precision, recall, and F1-score would all be the same in case all entities in the system output and the gold output are not NIL entities.\n",
    "\n",
    "**Example** For the example sentence above, let's say that a system made the following decisions:\n",
    "* \"JetBlue\" means http://dbpedia.org/resource/JetBlue (true positive)\n",
    "* \"Barnstable Airport\" means http://dbpedia.org/resource/Barnstable,_Massachusetts (false positive)\n",
    "* \"JFK\" means http://dbpedia.org/resource/John_F._Kennedy (false positive and false negative)\n",
    "\n",
    "Then, we have in total: `TP=1, FP=2, FN=1`. \n",
    "\n",
    "The resulting precision is `1/3=0.33` and the resulting recall is `1/2=0.5`. \n",
    "\n",
    "The F1-score of this system on this sentence would be `0.40`. \n",
    "\n",
    "### 5. An example evaluation in code\n",
    "\n",
    "Now we provide a code for this scenario. Note that for simplicity we assume that the entity recognition by the system is perfect. Also, we use a simple format of the gold and the system output as a list, in practice this requires some more preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_entity_linking(system_decisions, gold_decisions):\n",
    "    \"\"\"\n",
    "    Compute precision, recall, and F1-score by comparing two paired lists of: system decisions and gold data decisions.\n",
    "    \"\"\"\n",
    "    tp=0\n",
    "    fp=0\n",
    "    fn=0\n",
    "\n",
    "    for mention_id in range(num_entities):\n",
    "        gold_entity=gold_decisions[mention_id]\n",
    "        system_entity=system_decisions[mention_id]\n",
    "        if gold_entity=='NIL' and system_entity=='NIL': continue\n",
    "        if gold_entity==system_entity:\n",
    "            tp+=1\n",
    "        else:\n",
    "            if gold_entity!='NIL':\n",
    "                fn+=1\n",
    "            if system_entity!='NIL':\n",
    "                fp+=1\n",
    "\n",
    "    print('TP: %d; \\nFP: %d, \\nFN: %d' % (tp, fp, fn))            \n",
    "\n",
    "    precision=tp/(tp+fp)\n",
    "    recall=tp/(tp+fn)\n",
    "    f1=2*precision*recall/(precision+recall)\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 1; \n",
      "FP: 2, \n",
      "FN: 1\n",
      "Precision: 0.33, \n",
      "recall: 0.50, \n",
      "f1-score: 0.40\n"
     ]
    }
   ],
   "source": [
    "text=\"JetBlue begins direct service between Barnstable Airport and JFK.\"\n",
    "\n",
    "gold_decisions=['http://dbpedia.org/resource/JetBlue', \n",
    "                'NIL',\n",
    "                'http://dbpedia.org/resource/John_F._Kennedy_International_Airport']\n",
    "system_decisions=['http://dbpedia.org/resource/JetBlue', \n",
    "                  'http://dbpedia.org/resource/Barnstable,_Massachusetts',\n",
    "                 'http://dbpedia.org/resource/John_F._Kennedy']\n",
    "\n",
    "num_entities=len(gold_decisions)\n",
    "\n",
    "precision, recall, f1 = evaluate_entity_linking(system_decisions, gold_decisions)\n",
    "\n",
    "print('Precision: %.2f, \\nrecall: %.2f, \\nf1-score: %.2f' % (precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Disambiguating with existing tools\n",
    "\n",
    "Here we will load a small dataset called Reuters-128 which contains 128 news documents with annotated entity mentions with their links in DBpedia.\n",
    "\n",
    "Then we will parse this dataset with two modern tools, called AGDISTIS and DBpedia Spotlight.\n",
    "\n",
    "#### 6.1 Setup your environment\n",
    "\n",
    "**6.1.1 Install the needed modules**\n",
    "\n",
    "For the purpose of this module, we will need some new libraries that are probably not installed on your computer:\n",
    "* [rdflib](https://pypi.org/project/rdflib/)\n",
    "* [agdistispy](https://pypi.org/project/agdistispy/)\n",
    "* [pyspotlight](https://pypi.org/project/pyspotlight/)\n",
    "* [lxml](https://pypi.org/project/lxml/)\n",
    "\n",
    "You should install these libraries using `conda` or `pip`.\n",
    "\n",
    "Let's now check if all needed libraries are installed on your computer and can be imported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "import urllib\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import requests\n",
    "import urllib.parse\n",
    "import xml.etree.cElementTree as ET\n",
    "from lxml import etree\n",
    "import time\n",
    "\n",
    "from agdistispy.agdistis import Agdistis\n",
    "import spotlight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see any errors with the imports: \n",
    "* read the error carefully\n",
    "* install the library that is missing\n",
    "* try to execute the imports again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1.2 Let's download the N3 Reuters-128 dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will not work on Windows. \n",
    "# If you are running Windows, please download the dataset manually from \n",
    "# https://raw.githubusercontent.com/dice-group/n3-collection/master/Reuters-128.ttl .\n",
    "\n",
    "%%bash \n",
    "if [ ! -f Reuters-128.ttl ]; then\n",
    "    wget https://raw.githubusercontent.com/dice-group/n3-collection/master/Reuters-128.ttl\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above command executed successfully, then you should see the dataset file 'Reuters-128.ttl' in the same directory as this notebook. In case you experience any errors, you can download the dataset manually from https://raw.githubusercontent.com/dice-group/n3-collection/master/Reuters-128.ttl.\n",
    "\n",
    "This dataset contains 128 Reuters documents annotated with entity mentions and links to DBpedia. It is in a .ttl format called NIF (don't worry about these formats for now, we provide a function to parse this dataset to python classes).\n",
    "\n",
    "*Before proceding, please verify that your setup of libraries (6.1.1) is correct and that the dataset is downloaded in the right location (6.1.2).*\n",
    "\n",
    "#### 6.2 Load the data from N3\n",
    "\n",
    "**Let's now parse this dataset to a list of news items objects that contain the text and the entity mentions for each news item.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_file='Reuters-128.ttl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsItem:\n",
    "    \"\"\"\n",
    "    class containing information about a news item\n",
    "    \"\"\"\n",
    "    def __init__(self, identifier, content=\"\",\n",
    "                 dct=None):\n",
    "        self.identifier = identifier  # string, the original document name in the dataset\n",
    "        self.dct = dct                # e.g. \"2005-05-14T02:00:00.000+02:00\" -> document creation time\n",
    "        self.content = content        # the text of the news article\n",
    "        self.entity_mentions = []  # set of instances of EntityMention class\n",
    "        \n",
    "class EntityMention:\n",
    "    \"\"\"\n",
    "    class containing information about an entity mention\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mention,\n",
    "                 begin_index, end_index,\n",
    "                 gold_link=None,\n",
    "                 the_type=None, sentence=None, agdistis_link=None,\n",
    "                 spotlight_link=None): #, exact_match=False):\n",
    "        self.sentence = sentence         # e.g. 4 -> which sentence is the entity mentioned in\n",
    "        self.mention = mention           # e.g. \"John Smith\" -> the mention of an entity as found in text\n",
    "        self.the_type = the_type         # e.g. \"Person\" | \"http://dbpedia.org/ontology/Person\"\n",
    "        self.begin_index = begin_index   # e.g. 15 -> begin offset\n",
    "        self.end_index = end_index       # e.g. 25 -> end offset\n",
    "        self.gold_link = gold_link       # gold link if existing\n",
    "        self.agdistis_link = agdistis_link    # AGDISTIS link\n",
    "        self.spotlight_link = spotlight_link             # Spotlight link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeURL(s):\n",
    "    \"\"\"\n",
    "    Normalize a URI by removing its Wikipedia/DBpedia prefix.\n",
    "    \"\"\"\n",
    "    if s:\n",
    "        if s.startswith('http://aksw.org/notInWiki'):\n",
    "            return 'NIL'\n",
    "        else:\n",
    "            return urllib.parse.unquote(s.replace(\"http://en.wikipedia.org/wiki/\", \"\").\n",
    "                                        replace(\"http://dbpedia.org/resource/\", \"\"). \n",
    "                                        replace(\"http://dbpedia.org/page/\", \"\").\n",
    "                                        strip().\n",
    "                                        strip('\"'))\n",
    "    else:\n",
    "        return 'NIL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_article_from_nif_file(nif_file):\n",
    "    \"\"\"\n",
    "    Load a dataset in NIF format.\n",
    "    \"\"\"\n",
    "    g=Graph()\n",
    "    g.parse(nif_file, format=\"n3\")\n",
    "\n",
    "    news_items=[]\n",
    "\n",
    "    articles = g.query(\n",
    "    \"\"\" SELECT ?articleid ?date ?string\n",
    "    WHERE {\n",
    "        ?articleid nif:isString ?string .\n",
    "        OPTIONAL { ?articleid <http://purl.org/dc/elements/1.1/date> ?date . }\n",
    "    }\n",
    "    \"\"\")\n",
    "    for article in articles:\n",
    "        news_item_obj=NewsItem(\n",
    "            content=article['string'],\n",
    "            identifier=article['articleid'], \n",
    "            dct=article['date']\n",
    "        )\n",
    "        query=\"\"\" SELECT ?id ?mention ?start ?end ?gold\n",
    "        WHERE {\n",
    "            ?id nif:anchorOf ?mention ;\n",
    "            nif:beginIndex ?start ;\n",
    "            nif:endIndex ?end ;\n",
    "            nif:referenceContext <%s> .\n",
    "            OPTIONAL { ?id itsrdf:taIdentRef ?gold . }\n",
    "        } ORDER BY ?start\"\"\" % str(article['articleid'])\n",
    "        qres_entities = g.query(query)\n",
    "        for entity in qres_entities:\n",
    "            gold_link=normalizeURL(str(entity['gold']))\n",
    "            if gold_link.startswith('http://aksw.org/notInWiki'):\n",
    "                gold_link='NIL'\n",
    "            entity_obj = EntityMention(\n",
    "                begin_index=int(entity['start']),\n",
    "                end_index=int(entity['end']),\n",
    "                mention=str(entity['mention']),\n",
    "                gold_link=gold_link\n",
    "            )\n",
    "            news_item_obj.entity_mentions.append(entity_obj)\n",
    "        news_items.append(news_item_obj)\n",
    "    return news_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=load_article_from_nif_file(reuters_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 AGDISTIS\n",
    "\n",
    "AGDISTIS (also called Multilingual AGDISTIS, or MAG) is an entity linking system that puts all entity candidates in a graph network and then performs a probabilistic optimization to find the best connected candidate in this graph for each of the entity mentions. \n",
    "\n",
    "More description can be found in their paper: https://arxiv.org/pdf/1707.05288.pdf\n",
    "\n",
    "You can play with AGDISTIS by using their demo page: http://agdistis.aksw.org/demo/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = Agdistis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agdistis_disambiguation(articles):\n",
    "    \"\"\"\n",
    "    Perform disambiguation with AGDISTIS.\n",
    "    \"\"\"\n",
    "    with tqdm(total=len(articles), file=sys.stdout) as pbar:\n",
    "        for i, article in enumerate(articles):\n",
    "                                    \n",
    "            # AGDISTIS expects entity mentions that are pre-marked inside text. \n",
    "            # For example, the sentence \"Obama visited Paris today\", \n",
    "            # should be transformed to \"<entity>Obama</entity> visited <entity>Paris</entity> today.\"\n",
    "            # We do this in the next 5 lines of code.\n",
    "            original_content = article.content\n",
    "            new_content=original_content\n",
    "            for entity in reversed(article.entity_mentions):\n",
    "                entity_span=new_content[entity.begin_index: entity.end_index]\n",
    "                new_content=new_content[:entity.begin_index] + '<entity>' + entity_span + '</entity>' + new_content[entity.end_index:]\n",
    "\n",
    "            # Now, we can run the AGDISTIS library with this string.\n",
    "            results = ag.disambiguate(new_content)\n",
    "            \n",
    "            # Let's normalize the disambiguated entiies.\n",
    "            # This means mostly removing the first part of the URI which is always the same (http://dbpedia.org/resource)\n",
    "            # and leaving only the entity identification part (e.g., Barack_Obama).\n",
    "            dis_entities={}\n",
    "            for dis_entity in results:\n",
    "                dis_entities[str(dis_entity['start'])] = normalizeURL(dis_entity['disambiguatedURL'])\n",
    "                \n",
    "            # We can now store the entity to our class instance for later processing.\n",
    "            for entity in article.entity_mentions:\n",
    "                start = entity.begin_index\n",
    "                dis_url = dis_entities[str(start)]\n",
    "                entity.agdistis_link = dis_url\n",
    "\n",
    "            # The next two lines only update the progress bar\n",
    "            pbar.set_description('processed: %d' % (1 + i))\n",
    "            pbar.update(1)\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_agdistis=agdistis_disambiguation(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 DBpedia Spotlight\n",
    "\n",
    "DBpedia Spotlight is an entity recognition and linking tool that performs linking to DBpedia. The core of their method is a vector space model to compute similarity between the text to annotate and the Wikipedia pages of all entity candidates for a mention. Then the entities with largest similarity are chosen.\n",
    "\n",
    "Here is their paper: http://oa.upm.es/8923/1/DBpedia_Spotlight.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spotlight_disambiguate(articles, spotlight_url):\n",
    "    \"\"\"\n",
    "    Perform disambiguation with DBpedia Spotlight.\n",
    "    \"\"\"\n",
    "    with tqdm(total=len(articles), file=sys.stdout) as pbar:\n",
    "        for i, article in enumerate(articles):\n",
    "            # Similar as with AGDISTIS, we first prepare the document text and the mentions\n",
    "            # in order to provide these to Spotlight as input.\n",
    "            annotation = etree.Element(\"annotation\", text=article.content)\n",
    "            for mention in article.entity_mentions:\n",
    "                sf = etree.SubElement(annotation, \"surfaceForm\")\n",
    "                sf.set(\"name\", mention.mention)\n",
    "                sf.set(\"offset\", str(mention.begin_index))\n",
    "            my_xml=etree.tostring(annotation, xml_declaration=True, encoding='UTF-8')\n",
    "            \n",
    "            # Send a disambiguation request to spotlight\n",
    "            results=requests.post(spotlight_url, urllib.parse.urlencode({'text':my_xml, 'confidence': 0.5}), \n",
    "                                  headers={'Accept': 'application/json'})\n",
    "            \n",
    "            # Process the results and normalize the entity URIs\n",
    "            j=results.json()\n",
    "            dis_entities={}\n",
    "            if 'Resources' in j: \n",
    "                resources=j['Resources']\n",
    "            else: \n",
    "                resources=[]\n",
    "            for dis_entity in resources:\n",
    "                dis_entities[str(dis_entity['@offset'])] = normalizeURL(dis_entity['@URI'])\n",
    "            \n",
    "            # Let's now store the URLs by Spotlight to our class for later analysis.\n",
    "            for entity in article.entity_mentions:\n",
    "                start = entity.begin_index\n",
    "                if str(start) in dis_entities:\n",
    "                    dis_url = dis_entities[str(start)]\n",
    "                else:\n",
    "                    dis_url = 'NIL'\n",
    "                entity.spotlight_link = dis_url\n",
    "    \n",
    "            # The next two lines only update the progress bar\n",
    "            pbar.set_description('processed: %d' % (1 + i))\n",
    "            pbar.update(1)\n",
    "                \n",
    "            # Pause for 100ms to prevent overloading the server\n",
    "            time.sleep(0.1)\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spotlight_url=\"http://model.dbpedia-spotlight.org/en/disambiguate\" # Uses data from February 2018\n",
    "spotlight_url=\"http://spotlight.fii800.lod.labs.vu.nl/rest/disambiguate\" # Uses data from April 2016 (same as AGDISTIS)\n",
    "\n",
    "processed_spotlight=spotlight_disambiguate(processed_agdistis, spotlight_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 Comparing the output of AGDISTIS and Spotlight to the gold links\n",
    "\n",
    "Let's pick an article and print the decisions made by AGDISTIS and Spotlight on that article, and then compare that to the gold link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_number=3\n",
    "\n",
    "for m in articles[article_number].entity_mentions:\n",
    "    print('%s\\t%s\\t%s' % (m.gold_link, m.agdistis_link, m.spotlight_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Entity annotation from scratch: Performing recognition and disambiguation together\n",
    "\n",
    "Some tools only perform disambiguation (AGDISTIS is an example), whereas others (like Spotlight) can perform both recognition and disambiguation.\n",
    "\n",
    "Here we will use Spotlight annotate some text with entities without prior marking of entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''\n",
    "On November 24, Aziz Karimov, a journalist based in Baku, received an email from Facebook notifying him of a request to reset his password. \n",
    "Karimov knew something was wrong since he hadn’t requested a password change. \n",
    "Ninety minutes later, as he struggled to regain access to his account, he received four more notifications from Facebook. \n",
    "He was informed that he had also been removed as an administrator from four other pages, including one belonging to Turan News Agency, \n",
    "Azerbaijan’s only independent news agency.\n",
    "'''\n",
    "annotations = spotlight.annotate('http://model.dbpedia-spotlight.org/en/annotate',\n",
    "                                  text,\n",
    "                                  confidence=0.5, support=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
