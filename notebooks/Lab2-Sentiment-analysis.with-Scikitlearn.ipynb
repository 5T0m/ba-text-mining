{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab2 - Movie Reviews Sentiment Analysis with Scikit-Learn\n",
    "\n",
    "The focus of this notebook is on performing sentiment analysis using the scikit-learn package. Material from [this notebook](http://www.pitt.edu/~naraehan/presentation/Movie+Reviews+sentiment+analysis+with+Scikit-Learn.html) was used.\n",
    "\n",
    "**at the end of this notebook, you will be able to**:\n",
    "* load the training data, i.e., the movie reviews\n",
    "* inspect the training data, i.e., the movie reviews\n",
    "* extracting features from training data\n",
    "* training and evaluating the *NaiveBayesClassifier*\n",
    "* apply the classifier to fake movie reviews\n",
    "* creating your own gold standard\n",
    "\n",
    "**If you want to learn more, you might find the following links useful:**\n",
    "* [documentation on dataset loading](http://scikit-learn.org/stable/datasets/)\n",
    "* [introduction TF-IDF](https://medium.freecodecamp.org/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "We are first going to load and inspect the movie reviews dataset.\n",
    "However, we are going to use a general method to load the dataset.\n",
    "This is relevant for when you want to use other datasets as training data for the same algorithm.\n",
    "Let's first inspect what the help message of the function **load_files** states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_files in module sklearn.datasets.base:\n",
      "\n",
      "load_files(container_path, description=None, categories=None, load_content=True, shuffle=True, encoding=None, decode_error='strict', random_state=0)\n",
      "    Load text files with categories as subfolder names.\n",
      "    \n",
      "    Individual samples are assumed to be files stored a two levels folder\n",
      "    structure such as the following:\n",
      "    \n",
      "        container_folder/\n",
      "            category_1_folder/\n",
      "                file_1.txt\n",
      "                file_2.txt\n",
      "                ...\n",
      "                file_42.txt\n",
      "            category_2_folder/\n",
      "                file_43.txt\n",
      "                file_44.txt\n",
      "                ...\n",
      "    \n",
      "    The folder names are used as supervised signal label names. The individual\n",
      "    file names are not important.\n",
      "    \n",
      "    This function does not try to extract features into a numpy array or scipy\n",
      "    sparse matrix. In addition, if load_content is false it does not try to\n",
      "    load the files in memory.\n",
      "    \n",
      "    To use text files in a scikit-learn classification or clustering algorithm,\n",
      "    you will need to use the `sklearn.feature_extraction.text` module to build\n",
      "    a feature extraction transformer that suits your problem.\n",
      "    \n",
      "    If you set load_content=True, you should also specify the encoding of the\n",
      "    text using the 'encoding' parameter. For many modern text files, 'utf-8'\n",
      "    will be the correct encoding. If you leave encoding equal to None, then the\n",
      "    content will be made of bytes instead of Unicode, and you will not be able\n",
      "    to use most functions in `sklearn.feature_extraction.text`.\n",
      "    \n",
      "    Similar feature extractors should be built for other kind of unstructured\n",
      "    data input such as images, audio, video, ...\n",
      "    \n",
      "    Read more in the :ref:`User Guide <datasets>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    container_path : string or unicode\n",
      "        Path to the main folder holding one subfolder per category\n",
      "    \n",
      "    description : string or unicode, optional (default=None)\n",
      "        A paragraph describing the characteristic of the dataset: its source,\n",
      "        reference, etc.\n",
      "    \n",
      "    categories : A collection of strings or None, optional (default=None)\n",
      "        If None (default), load all the categories. If not None, list of\n",
      "        category names to load (other categories ignored).\n",
      "    \n",
      "    load_content : boolean, optional (default=True)\n",
      "        Whether to load or not the content of the different files. If true a\n",
      "        'data' attribute containing the text information is present in the data\n",
      "        structure returned. If not, a filenames attribute gives the path to the\n",
      "        files.\n",
      "    \n",
      "    shuffle : bool, optional (default=True)\n",
      "        Whether or not to shuffle the data: might be important for models that\n",
      "        make the assumption that the samples are independent and identically\n",
      "        distributed (i.i.d.), such as stochastic gradient descent.\n",
      "    \n",
      "    encoding : string or None (default is None)\n",
      "        If None, do not try to decode the content of the files (e.g. for images\n",
      "        or other non-text content). If not None, encoding to use to decode text\n",
      "        files to Unicode if load_content is True.\n",
      "    \n",
      "    decode_error : {'strict', 'ignore', 'replace'}, optional\n",
      "        Instruction on what to do if a byte sequence is given to analyze that\n",
      "        contains characters not of the given `encoding`. Passed as keyword\n",
      "        argument 'errors' to bytes.decode.\n",
      "    \n",
      "    random_state : int, RandomState instance or None (default=0)\n",
      "        Determines random number generation for dataset shuffling. Pass an int\n",
      "        for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    data : Bunch\n",
      "        Dictionary-like object, the interesting attributes are: either\n",
      "        data, the raw text data to learn, or 'filenames', the files\n",
      "        holding it, 'target', the classification labels (integer index),\n",
      "        'target_names', the meaning of the labels, and 'DESCR', the full\n",
      "        description of the dataset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the function requires the following structure in order for it to work:\n",
    "* container_folder/\n",
    "    * category_1_folder/ (e.g., 'pos')\n",
    "        * file_1.txt\n",
    "        * file_2.txt\n",
    "        * ...\n",
    "        file_42.txt\n",
    "    * category_2_folder/ (e.g., 'neg')\n",
    "        * file_43.txt\n",
    "        * file_44.txt\n",
    "        * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether our **movie_review** corpus has this structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path to corpus on your computer /Users/marten/nltk_data/corpora/movie_reviews\n"
     ]
    }
   ],
   "source": [
    "print('path to corpus on your computer', movie_reviews._root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the command line or using Mac Finder or equivalent on Windows, please go the movie_reviews folder and inspect whether the corpus has the required structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, it is! Let's now load it using the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/marten/nltk_data/corpora/movie_reviews\n"
     ]
    }
   ],
   "source": [
    "# Please change the path here if you want to train it on a different corpus!\n",
    "moviedir = str(movie_reviews._root)\n",
    "print(moviedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all files as training data. \n",
    "movie_train = load_files(moviedir, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many files do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target names (\"classes\") are automatically generated from subfolder names\n",
    "movie_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so cal\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's inspect one file\n",
    "movie_train.data[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/marten/nltk_data/corpora/movie_reviews/neg/cv405_21868.txt'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first file is in \"neg\" folder\n",
    "movie_train.filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first file is a negative review and is mapped to 0 index 'neg' in target_names\n",
    "movie_train.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A detour: try out CountVectorizer & TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "# Turn off pretty printing of jupyter notebook... it generates long lines\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = ['A rose is a rose is a rose is a rose.',\n",
    "         'Oh, what a fine day it is.',\n",
    "        \"It ain't over till it's over, I tell you!!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a CoutVectorizer to use NLTK's tokenizer instead of its \n",
    "# default one (which ignores punctuation and stopwords). \n",
    "# Minimum document frequency set to 1. \n",
    "foovec = CountVectorizer(min_df=1, tokenizer=nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 4, 'rose': 14, 'is': 9, '.': 3, 'oh': 12, ',': 2, 'what': 17, 'fine': 7, 'day': 6, 'it': 10, 'ai': 5, \"n't\": 11, 'over': 13, 'till': 16, \"'s\": 1, 'i': 8, 'tell': 15, 'you': 18, '!': 0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sents turned into sparse vector of word frequency counts\n",
    "sents_counts = foovec.fit_transform(sents)\n",
    "# foovec now contains vocab dictionary which maps unique words to indexes\n",
    "foovec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 19)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sents_counts has a dimension of 3 (document count) by 19 (# of unique words)\n",
    "sents_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 4, 0, 0, 0, 0, 3, 0, 0, 0, 0, 4, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [2, 1, 1, 0, 0, 1, 0, 0, 1, 0, 2, 1, 0, 2, 0, 1, 1, 0, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this vector is small enough to view in full! \n",
    "sents_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw frequency counts into TF-IDF (Term Frequency -- Inverse Document Frequency) values\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "sents_tfidf = tfidf_transformer.fit_transform(sents_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.13650997, 0.54603988,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.40952991,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.71797683,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.28969526, 0.28969526, 0.28969526,\n",
       "        0.        , 0.38091445, 0.38091445, 0.        , 0.28969526,\n",
       "        0.28969526, 0.        , 0.38091445, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.38091445, 0.        ],\n",
       "       [0.47282517, 0.23641258, 0.17979786, 0.        , 0.        ,\n",
       "        0.23641258, 0.        , 0.        , 0.23641258, 0.        ,\n",
       "        0.35959573, 0.23641258, 0.        , 0.47282517, 0.        ,\n",
       "        0.23641258, 0.23641258, 0.        , 0.23641258]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF values\n",
    "# raw counts have been normalized against document length, \n",
    "# terms that are found across many docs are weighted down\n",
    "sents_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features from training data\n",
    "Instead of using the words as features, we are going to represent each movie review using a vector. This vector has the length of the amount of terms that there are in all the movie reviews combined. Instead of a cell value being the frequency of occurrence, we use it's td-idf value (as shown above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize movie_vector object, and then turn movie train data into a vector \n",
    "movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize)\n",
    "movie_counts = movie_vec.fit_transform(movie_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19603"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'screen' is found in the corpus, mapped to index 19637\n",
    "movie_vec.vocabulary_.get('screen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19656"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Likewise, Mr. Steven Seagal is present...\n",
    "movie_vec.vocabulary_.get('seagal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 25279)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# huge dimensions! 2,000 documents, 25K unique terms. \n",
    "movie_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw frequency counts into TF-IDF values\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "movie_tfidf = tfidf_transformer.fit_transform(movie_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 25279)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same dimensions, now with tf-idf values instead of raw frequency counts\n",
    "movie_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing a Naive Bayes classifier\n",
    "In order to train the classifier, we will first split the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now ready to build a classifier. \n",
    "# We will use Multinominal Naive Bayes as our model\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "# from sklearn.cross_validation import train_test_split  # deprecated in 0.18\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again choose 80% training and 20% test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    movie_tfidf, \n",
    "    movie_train.target, \n",
    "    test_size = 0.20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One instance looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x25279 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 310 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's label is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Multimoda Naive Bayes classifier\n",
    "clf = MultinomialNB().fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results, find accuracy\n",
    "y_pred = clf.predict(docs_test)\n",
    "sklearn.metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying classifier on fake movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# very short and fake movie reviews\n",
    "reviews_new = ['This movie was excellent', 'Absolute joy ride', \n",
    "            'Steven Seagal was terrible', 'Steven Seagal shined through.', \n",
    "              'This was certainly a movie', 'Two thumbs up', 'I fell asleep halfway through', \n",
    "              \"We can't wait for the sequel!!\", '!', '?', 'I cannot recommend this highly enough', \n",
    "              'instant classic.', 'Steven Seagal was amazing. His performance was Oscar-worthy.']\n",
    "len(reviews_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We re-use movie_vec to transform it in the same way as the training data\n",
    "reviews_new_counts = movie_vec.transform(reviews_new)\n",
    "reviews_new_tfidf = tfidf_transformer.transform(reviews_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 25279)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dimensions for the 13 reviews are the same\n",
    "reviews_new_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have classifier make a prediction\n",
    "pred = clf.predict(reviews_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 1 0 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Note that the predictions are just an array with the class result for the 13 reviews\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie was excellent => pos\n",
      "Absolute joy ride => pos\n",
      "Steven Seagal was terrible => neg\n",
      "Steven Seagal shined through. => neg\n",
      "This was certainly a movie => neg\n",
      "Two thumbs up => pos\n",
      "I fell asleep halfway through => neg\n",
      "We can't wait for the sequel!! => neg\n",
      "! => neg\n",
      "? => neg\n",
      "I cannot recommend this highly enough => pos\n",
      "instant classic. => pos\n",
      "Steven Seagal was amazing. His performance was Oscar-worthy. => neg\n"
     ]
    }
   ],
   "source": [
    "# print out results\n",
    "for review, category in zip(reviews_new, pred):\n",
    "    print('%s => %s' % (review, movie_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your own gold standard\n",
    "You can make your own gold standard in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_new = ['This movie was excellent', 'Absolute joy ride', \n",
    "            'Steven Seagal was terrible', 'Steven Seagal shined through.', \n",
    "              'This was certainly a movie', 'Two thumbs up', 'I fell asleep halfway through', \n",
    "              \"We can't wait for the sequel!!\", '!', '?', 'I cannot recommend this highly enough', \n",
    "              'instant classic.', 'Steven Seagal was amazing. His performance was Oscar-worthy.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each review in **reviews_new**, we determine whether it was positive (1) or negative (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_values = [1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We turn it into the data type needed by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(13,)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "gold = numpy.array(gold_values, numpy.int64)\n",
    "print(type(gold))\n",
    "print(gold.shape)\n",
    "print(gold.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie was excellent => pos\n",
      "Absolute joy ride => pos\n",
      "Steven Seagal was terrible => neg\n",
      "Steven Seagal shined through. => pos\n",
      "This was certainly a movie => pos\n",
      "Two thumbs up => neg\n",
      "I fell asleep halfway through => pos\n",
      "We can't wait for the sequel!! => neg\n",
      "! => neg\n",
      "? => neg\n",
      "I cannot recommend this highly enough => neg\n",
      "instant classic. => pos\n",
      "Steven Seagal was amazing. His performance was Oscar-worthy. => pos\n"
     ]
    }
   ],
   "source": [
    "# print out the gold standard\n",
    "for review, category in zip(reviews_new, gold):\n",
    "    print('%s => %s' % (review, movie_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### We can now directly get the accuracy\n",
    "sklearn.metrics.accuracy_score(gold, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.42857142857142855\n",
      "precision: 0.6\n",
      "f-measure: 0.5\n"
     ]
    }
   ],
   "source": [
    "### We can now directly get the recall, precision and f1-score\n",
    "print(\"recall:\",sklearn.metrics.recall_score(gold, pred))\n",
    "print(\"precision:\",sklearn.metrics.precision_score(gold, pred))\n",
    "print(\"f-measure:\",sklearn.metrics.f1_score(gold, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion-matrix: [[4 2]\n",
      " [4 3]]\n"
     ]
    }
   ],
   "source": [
    "print(\"confusion-matrix:\",sklearn.metrics.confusion_matrix(gold, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         6\n",
      "           1       0.60      0.43      0.50         7\n",
      "\n",
      "   micro avg       0.54      0.54      0.54        13\n",
      "   macro avg       0.55      0.55      0.54        13\n",
      "weighted avg       0.55      0.54      0.53        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(gold, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
