{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis with NLTK:\n",
    "\n",
    "http://www.nltk.org/api/nltk.sentiment.html#module-nltk.sentiment.util\n",
    "\n",
    "https://www.nltk.org/book/ch06.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next assignment you are going to work with a variety of sentiment analysis tools. To test these tools, you need to make a test set of 60 tweets. Divide these into 3 sets: positive, negative and neutral. Describe how you obtained the tweets and how they were divided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We first are going to use the VADER package inside NLTK to get the sentiment for some input texts\n",
    "More information on VADER can be found in the original source code repository:\n",
    "\n",
    "https://github.com/cjhutto/vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/piek/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/piek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import sentiment\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import sentiment\n",
    "from nltk import word_tokenize\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize VADER so we can use it within our Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a tokenizer to split a text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take an arbitrary text and split it into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here are my sentences.', \"It's a nice day.\", \"It's a rainy day.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define some text\n",
    "sometext = \"Here are my sentences. It's a nice day. It's a rainy day.\" \n",
    "sentences = tokenizer.tokenize(sometext)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next for loop assigns a sentiment score from VADER to each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are my sentences.\n",
      "compound: 0.0516, \n",
      "neg: 0.0, \n",
      "neu: 0.714, \n",
      "pos: 0.286, \n",
      "It's a nice day.\n",
      "compound: 0.4215, \n",
      "neg: 0.0, \n",
      "neu: 0.417, \n",
      "pos: 0.583, \n",
      "It's a rainy day.\n",
      "compound: -0.0772, \n",
      "neg: 0.394, \n",
      "neu: 0.606, \n",
      "pos: 0.0, \n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    scores = vader.polarity_scores(sentence)\n",
    "    for key in sorted(scores):\n",
    "        print('{0}: {1}, '.format(key, scores[key]), end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "Now run the VADER package on you tweet test set and report on the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though sentiment analysis can be a powerful tool for quickly determining the emotions expressed through text, there are limitations to what sentiment analysis can provide. Additionally, like all text analysis, we need to be cautious in interpreting the results. For example, sentences that contain profanity have a tendency to be interpreted by NLTK as negative; this can be a problem when using texts from social media, where profanity is often used for emphasis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIEK: This is probably too ambituous\n",
    "Download the VADER package from the original GITHUB and try to build a local installation.\n",
    "Modify the lexicon and try to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a NaiveBayesClassifier with \n",
    "\n",
    "https://www.nltk.org/book/ch06.html\n",
    "\n",
    "* section 6.1\n",
    "* section 6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "# Loading stuff\n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import * # needed for the mark_negation function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the datasets (subjective and objective sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first obtain the subjectivity corpus that is included in NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this data set we are going to select 200 sentences for training and testing.\n",
    "The package subjectivity.sents defines which sentences are subjective ('subj') and which ones are objective ('obj')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_instances = 100\n",
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]\n",
    "len(subj_docs), len(obj_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now balanced. Why is this important for a NaiveBayesClassifier? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Document is represented by a tuple (ie. in the form <sentence, label>. The sentence is tokenised, so it is represented by a list of strings. The labels is subj or obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"there's\",\n",
       "  'lots',\n",
       "  'of',\n",
       "  'cool',\n",
       "  'stuff',\n",
       "  'packed',\n",
       "  'into',\n",
       "  \"espn's\",\n",
       "  'ultimate',\n",
       "  'x',\n",
       "  '.'],\n",
       " 'subj')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_docs[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subjective and objective instances were split separately, to keep a balanced uniform class distribution in both train and test sets. We create the train and test set by taking the first 80 sentences as train and the last 20 sentences as test. We then concatenate the subjective and objective sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj_docs = subj_docs[:80]\n",
    "test_subj_docs = subj_docs[80:100]\n",
    "train_obj_docs = obj_docs[:80]\n",
    "test_obj_docs = obj_docs[80:100]\n",
    "training_docs = train_subj_docs+train_obj_docs\n",
    "testing_docs = test_subj_docs+test_obj_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initialize a SentimentAnalyser and use a mark_negation function for negative words. mark_negationis a utility function that marks words that are negations that can switch the polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentim_analyzer = SentimentAnalyzer()\n",
    "all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple unigram word features are then used, handling negation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "len(unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'the',\n",
       " ',',\n",
       " 'a',\n",
       " 'and',\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'in',\n",
       " 'with',\n",
       " 'it',\n",
       " 'that',\n",
       " 'his',\n",
       " 'on',\n",
       " 'for',\n",
       " 'an',\n",
       " 'who',\n",
       " 'by',\n",
       " 'he',\n",
       " 'from',\n",
       " 'her',\n",
       " '\"',\n",
       " 'film',\n",
       " 'as',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'their',\n",
       " 'but',\n",
       " 'one',\n",
       " 'at',\n",
       " 'about',\n",
       " 'the_NEG',\n",
       " 'a_NEG',\n",
       " 'to_NEG',\n",
       " 'are',\n",
       " \"there's\",\n",
       " '(',\n",
       " 'story',\n",
       " 'when',\n",
       " 'so',\n",
       " 'be',\n",
       " ',_NEG',\n",
       " ')',\n",
       " 'they',\n",
       " 'you',\n",
       " 'not',\n",
       " 'have',\n",
       " 'like',\n",
       " 'will',\n",
       " 'all',\n",
       " 'into',\n",
       " 'out',\n",
       " 'she',\n",
       " 'what',\n",
       " 'life',\n",
       " 'has',\n",
       " 'its',\n",
       " 'only',\n",
       " 'more',\n",
       " 'even',\n",
       " '--',\n",
       " ':',\n",
       " 'can',\n",
       " ';',\n",
       " 'home',\n",
       " 'look',\n",
       " \"it's\",\n",
       " 'if',\n",
       " 'where',\n",
       " 'most',\n",
       " 'him',\n",
       " 'search',\n",
       " 'but_NEG',\n",
       " 'love',\n",
       " 'both',\n",
       " 'make',\n",
       " 'begins',\n",
       " 'some',\n",
       " 'two',\n",
       " 'of_NEG',\n",
       " 'made',\n",
       " 'which',\n",
       " 'them']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, features are applied to obtain a feature-value representation of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = sentim_analyzer.apply_features(training_docs)\n",
    "test_set = sentim_analyzer.apply_features(testing_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the feature presentation of the test_set. Do you understand what it represents? Why are so many features False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'contains(.)': True, 'contains(the)': True, 'contains(,)': False, 'contains(a)': True, 'contains(and)': False, 'contains(of)': True, 'contains(to)': False, 'contains(is)': False, 'contains(in)': False, 'contains(with)': True, 'contains(it)': False, 'contains(that)': False, 'contains(his)': False, 'contains(on)': False, 'contains(for)': True, 'contains(an)': False, 'contains(who)': False, 'contains(by)': False, 'contains(he)': False, 'contains(from)': False, 'contains(her)': False, 'contains(\")': False, 'contains(film)': False, 'contains(as)': False, 'contains(this)': False, 'contains(movie)': False, 'contains(their)': False, 'contains(but)': False, 'contains(one)': False, 'contains(at)': False, 'contains(about)': False, 'contains(the_NEG)': False, 'contains(a_NEG)': False, 'contains(to_NEG)': False, 'contains(are)': False, \"contains(there's)\": False, 'contains(()': False, 'contains(story)': False, 'contains(when)': False, 'contains(so)': False, 'contains(be)': False, 'contains(,_NEG)': False, 'contains())': False, 'contains(they)': False, 'contains(you)': False, 'contains(not)': False, 'contains(have)': False, 'contains(like)': False, 'contains(will)': False, 'contains(all)': False, 'contains(into)': False, 'contains(out)': False, 'contains(she)': False, 'contains(what)': False, 'contains(life)': False, 'contains(has)': False, 'contains(its)': False, 'contains(only)': False, 'contains(more)': False, 'contains(even)': False, 'contains(--)': False, 'contains(:)': False, 'contains(can)': False, 'contains(;)': False, 'contains(home)': False, 'contains(look)': False, \"contains(it's)\": False, 'contains(if)': False, 'contains(where)': False, 'contains(most)': False, 'contains(him)': False, 'contains(search)': False, 'contains(but_NEG)': False, 'contains(love)': False, 'contains(both)': False, 'contains(make)': False, 'contains(begins)': False, 'contains(some)': False, 'contains(two)': False, 'contains(of_NEG)': False, 'contains(made)': False, 'contains(which)': False, 'contains(them)': False}, 'subj'), ({'contains(.)': True, 'contains(the)': False, 'contains(,)': True, 'contains(a)': True, 'contains(and)': True, 'contains(of)': False, 'contains(to)': True, 'contains(is)': True, 'contains(in)': True, 'contains(with)': False, 'contains(it)': True, 'contains(that)': True, 'contains(his)': False, 'contains(on)': False, 'contains(for)': True, 'contains(an)': False, 'contains(who)': False, 'contains(by)': False, 'contains(he)': False, 'contains(from)': False, 'contains(her)': False, 'contains(\")': False, 'contains(film)': True, 'contains(as)': False, 'contains(this)': False, 'contains(movie)': False, 'contains(their)': False, 'contains(but)': False, 'contains(one)': False, 'contains(at)': False, 'contains(about)': False, 'contains(the_NEG)': False, 'contains(a_NEG)': False, 'contains(to_NEG)': False, 'contains(are)': False, \"contains(there's)\": False, 'contains(()': False, 'contains(story)': False, 'contains(when)': False, 'contains(so)': False, 'contains(be)': False, 'contains(,_NEG)': False, 'contains())': False, 'contains(they)': False, 'contains(you)': False, 'contains(not)': False, 'contains(have)': True, 'contains(like)': False, 'contains(will)': True, 'contains(all)': False, 'contains(into)': False, 'contains(out)': True, 'contains(she)': False, 'contains(what)': False, 'contains(life)': False, 'contains(has)': False, 'contains(its)': False, 'contains(only)': False, 'contains(more)': False, 'contains(even)': False, 'contains(--)': False, 'contains(:)': False, 'contains(can)': False, 'contains(;)': False, 'contains(home)': False, 'contains(look)': False, \"contains(it's)\": False, 'contains(if)': False, 'contains(where)': False, 'contains(most)': False, 'contains(him)': False, 'contains(search)': False, 'contains(but_NEG)': False, 'contains(love)': False, 'contains(both)': True, 'contains(make)': False, 'contains(begins)': False, 'contains(some)': False, 'contains(two)': False, 'contains(of_NEG)': False, 'contains(made)': False, 'contains(which)': False, 'contains(them)': False}, 'subj'), ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we are ready to train our classifier on the training set, and output the evaluation results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n",
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.8\n",
      "F-measure [obj]: 0.8\n",
      "F-measure [subj]: 0.8\n",
      "Precision [obj]: 0.8\n",
      "Precision [subj]: 0.8\n",
      "Recall [obj]: 0.8\n",
      "Recall [subj]: 0.8\n"
     ]
    }
   ],
   "source": [
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)\n",
    "# output: Training classifier\n",
    "for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):\n",
    "    print('{0}: {1}'.format(key, value))\n",
    "#Outputs:\n",
    "#Evaluating NaiveBayesClassifier results...\n",
    "#Accuracy: 0.8\n",
    "#F-measure [obj]: 0.8\n",
    "#F-measure [subj]: 0.8\n",
    "#Precision [obj]: 0.8\n",
    "#Precision [subj]: 0.8\n",
    "#Recall [obj]: 0.8\n",
    "#Recall [subj]: 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a positive and negative classifier from movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first are going to load the movie_reviews data set from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    " \n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    " \n",
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "\n",
    "print(len(negids), len(posids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two data sets, one with the files that are negative reviews and one with the files that are positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg/cv000_29416.txt'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First negative review:\n",
    "negids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next are going to extract texts from each sub data set and create tuples with the labels 'neg' and 'pos', where the first element is the feature representation of the words of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'plot': True, ':': True, 'two': True, 'teen': True, 'couples': True, 'go': True, 'to': True, 'a': True, 'church': True, 'party': True, ',': True, 'drink': True, 'and': True, 'then': True, 'drive': True, '.': True, 'they': True, 'get': True, 'into': True, 'an': True, 'accident': True, 'one': True, 'of': True, 'the': True, 'guys': True, 'dies': True, 'but': True, 'his': True, 'girlfriend': True, 'continues': True, 'see': True, 'him': True, 'in': True, 'her': True, 'life': True, 'has': True, 'nightmares': True, 'what': True, \"'\": True, 's': True, 'deal': True, '?': True, 'watch': True, 'movie': True, '\"': True, 'sorta': True, 'find': True, 'out': True, 'critique': True, 'mind': True, '-': True, 'fuck': True, 'for': True, 'generation': True, 'that': True, 'touches': True, 'on': True, 'very': True, 'cool': True, 'idea': True, 'presents': True, 'it': True, 'bad': True, 'package': True, 'which': True, 'is': True, 'makes': True, 'this': True, 'review': True, 'even': True, 'harder': True, 'write': True, 'since': True, 'i': True, 'generally': True, 'applaud': True, 'films': True, 'attempt': True, 'break': True, 'mold': True, 'mess': True, 'with': True, 'your': True, 'head': True, 'such': True, '(': True, 'lost': True, 'highway': True, '&': True, 'memento': True, ')': True, 'there': True, 'are': True, 'good': True, 'ways': True, 'making': True, 'all': True, 'types': True, 'these': True, 'folks': True, 'just': True, 'didn': True, 't': True, 'snag': True, 'correctly': True, 'seem': True, 'have': True, 'taken': True, 'pretty': True, 'neat': True, 'concept': True, 'executed': True, 'terribly': True, 'so': True, 'problems': True, 'well': True, 'its': True, 'main': True, 'problem': True, 'simply': True, 'too': True, 'jumbled': True, 'starts': True, 'off': True, 'normal': True, 'downshifts': True, 'fantasy': True, 'world': True, 'you': True, 'as': True, 'audience': True, 'member': True, 'no': True, 'going': True, 'dreams': True, 'characters': True, 'coming': True, 'back': True, 'from': True, 'dead': True, 'others': True, 'who': True, 'look': True, 'like': True, 'strange': True, 'apparitions': True, 'disappearances': True, 'looooot': True, 'chase': True, 'scenes': True, 'tons': True, 'weird': True, 'things': True, 'happen': True, 'most': True, 'not': True, 'explained': True, 'now': True, 'personally': True, 'don': True, 'trying': True, 'unravel': True, 'film': True, 'every': True, 'when': True, 'does': True, 'give': True, 'me': True, 'same': True, 'clue': True, 'over': True, 'again': True, 'kind': True, 'fed': True, 'up': True, 'after': True, 'while': True, 'biggest': True, 'obviously': True, 'got': True, 'big': True, 'secret': True, 'hide': True, 'seems': True, 'want': True, 'completely': True, 'until': True, 'final': True, 'five': True, 'minutes': True, 'do': True, 'make': True, 'entertaining': True, 'thrilling': True, 'or': True, 'engaging': True, 'meantime': True, 'really': True, 'sad': True, 'part': True, 'arrow': True, 'both': True, 'dig': True, 'flicks': True, 'we': True, 'actually': True, 'figured': True, 'by': True, 'half': True, 'way': True, 'point': True, 'strangeness': True, 'did': True, 'start': True, 'little': True, 'bit': True, 'sense': True, 'still': True, 'more': True, 'guess': True, 'bottom': True, 'line': True, 'movies': True, 'should': True, 'always': True, 'sure': True, 'before': True, 'given': True, 'password': True, 'enter': True, 'understanding': True, 'mean': True, 'showing': True, 'melissa': True, 'sagemiller': True, 'running': True, 'away': True, 'visions': True, 'about': True, '20': True, 'throughout': True, 'plain': True, 'lazy': True, '!': True, 'okay': True, 'people': True, 'chasing': True, 'know': True, 'need': True, 'how': True, 'giving': True, 'us': True, 'different': True, 'offering': True, 'further': True, 'insight': True, 'down': True, 'apparently': True, 'studio': True, 'took': True, 'director': True, 'chopped': True, 'themselves': True, 'shows': True, 'might': True, 've': True, 'been': True, 'decent': True, 'here': True, 'somewhere': True, 'suits': True, 'decided': True, 'turning': True, 'music': True, 'video': True, 'edge': True, 'would': True, 'actors': True, 'although': True, 'wes': True, 'bentley': True, 'seemed': True, 'be': True, 'playing': True, 'exact': True, 'character': True, 'he': True, 'american': True, 'beauty': True, 'only': True, 'new': True, 'neighborhood': True, 'my': True, 'kudos': True, 'holds': True, 'own': True, 'entire': True, 'feeling': True, 'unraveling': True, 'overall': True, 'doesn': True, 'stick': True, 'because': True, 'entertain': True, 'confusing': True, 'rarely': True, 'excites': True, 'feels': True, 'redundant': True, 'runtime': True, 'despite': True, 'ending': True, 'explanation': True, 'craziness': True, 'came': True, 'oh': True, 'horror': True, 'slasher': True, 'flick': True, 'packaged': True, 'someone': True, 'assuming': True, 'genre': True, 'hot': True, 'kids': True, 'also': True, 'wrapped': True, 'production': True, 'years': True, 'ago': True, 'sitting': True, 'shelves': True, 'ever': True, 'whatever': True, 'skip': True, 'where': True, 'joblo': True, 'nightmare': True, 'elm': True, 'street': True, '3': True, '7': True, '/': True, '10': True, 'blair': True, 'witch': True, '2': True, 'crow': True, '9': True, 'salvation': True, '4': True, 'stir': True, 'echoes': True, '8': True}, 'neg')\n"
     ]
    }
   ],
   "source": [
    "negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "\n",
    "# lets print the first tuple from the negative set\n",
    "print(negfeats[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "# Define a split over the data for creating a train and test set\n",
    "negcutoff = int(len(negfeats)*3/4)\n",
    "poscutoff = int(len(posfeats)*3/4)\n",
    "\n",
    "print(negcutoff)\n",
    "print(poscutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1500 instances, test on 500 instances\n"
     ]
    }
   ],
   "source": [
    "trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "print('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.728\n",
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "print('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to create your own train and test set with labels SPAM and NOTSPAM or POS and NEG and see if you can train a NaiveBayesClassifier in the same way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You first need to find out how to create a data set with labels for training and testing.\n",
    "Check out the subjectivity on your local disk that is included in the NLTK download.\n",
    "On a mac you can find it below /Users/<your username>, e.g.:\n",
    "\n",
    "/Users/piek/nltl_data/corpora/subjectivity\n",
    "\n",
    "On a Windows or Linux machine it is in a slightly different path also in your user directory.\n",
    "\n",
    "Read the README.txt file that comes with the data:\n",
    "\n",
    "  * quote.tok.gt9.5000 contains 5000 subjective sentences (or snippets);\n",
    "\n",
    "  * plot.tok.gt9.5000 contains 5000 objective sentences.\n",
    "  \n",
    "https://www.nltk.org/_modules/nltk/corpus/reader/categorized_sents.html\n",
    "  \n",
    "In order to create another data set you need to create the tuples consisting of a sentence and a label.\n",
    "Remember that we used the subjectivity.sents function to load the tuples from the corpus:\n",
    "\n",
    "n_instances = 100\n",
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subjectivity packages uses a specific format and function to create the tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['smart',\n",
       "   'and',\n",
       "   'alert',\n",
       "   ',',\n",
       "   'thirteen',\n",
       "   'conversations',\n",
       "   'about',\n",
       "   'one',\n",
       "   'thing',\n",
       "   'is',\n",
       "   'a',\n",
       "   'small',\n",
       "   'gem',\n",
       "   '.'],\n",
       "  'subj'),\n",
       " (['color',\n",
       "   ',',\n",
       "   'musical',\n",
       "   'bounce',\n",
       "   'and',\n",
       "   'warm',\n",
       "   'seas',\n",
       "   'lapping',\n",
       "   'on',\n",
       "   'island',\n",
       "   'shores',\n",
       "   '.',\n",
       "   'and',\n",
       "   'just',\n",
       "   'enough',\n",
       "   'science',\n",
       "   'to',\n",
       "   'send',\n",
       "   'you',\n",
       "   'home',\n",
       "   'thinking',\n",
       "   '.'],\n",
       "  'subj')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check out the first two items to see how it is structured\n",
    "subj_docs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a very simple example that shows how you can create tuples from two simple sentences, turn them into word features and train a NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'I': True}, 'pos'), ({'l': True, 'i': True, 'k': True, 'e': True}, 'pos'), ({'g': True, 'r': True, 'e': True, 'n': True}, 'pos'), ({'e': True, 'g': True, 's': True}, 'pos'), ({'a': True, 'n': True, 'd': True}, 'pos'), ({'h': True, 'a': True, 'm': True}, 'pos'), ({',': True}, 'pos'), ({'a': True, 'n': True, 'd': True}, 'pos'), ({'I': True}, 'pos'), ({'l': True, 'i': True, 'k': True, 'e': True}, 'pos'), ({'t': True, 'h': True, 'e': True, 'm': True}, 'pos'), ({'t': True, 'o': True}, 'pos'), ({'!': True}, 'pos')]\n"
     ]
    }
   ],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "#from nltk.corpus import names\n",
    "\n",
    "# simple function that turns a list of words into word_feats (word features)\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "# In a lexical approach, you would predefine the positive, negative and neutral words and only use these to train a classifier\n",
    "positive_vocab = [ 'awesome', 'outstanding', 'fantastic', 'terrific', 'good', 'nice', 'great', ':)' ]\n",
    "negative_vocab = [ 'bad', 'terrible','useless', 'hate', ':(' ]\n",
    "neutral_vocab = [ 'movie','the','sound','was','is','actors','did','know','words','not' ]\n",
    "\n",
    "# Assume you have a collections of texts that are negative and neutral\n",
    "negsentence = \"I do not like green eggs and ham, and I do not like them too!\"\n",
    "possentence = \"I like green eggs and ham, and I like them too!\"\n",
    "# By using the tokenization function, you can turn them into word negative and positive lists\n",
    "negtokens = nltk.word_tokenize(negsentence)\n",
    "postokens = nltk.word_tokenize(possentence)\n",
    "\n",
    "# Next we use the simple word feature function to turn them into features that can be used for training the classifier \n",
    "positive_features = [(word_feats(pos), 'pos') for pos in postokens]\n",
    "negative_features = [(word_feats(neg), 'neg') for neg in negtokens]\n",
    "# for neural we now take the vocabulary given above\n",
    "neutral_features = [(word_feats(neu), 'neu') for neu in neutral_vocab]\n",
    "print(positive_features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would be another way to obtain neutral word features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you do this for a data set where positive and negative texts are stored in two separate directories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we simply concatenate the features to create a training set\n",
    "train_set = negative_features + positive_features + neutral_features\n",
    "classifier = NaiveBayesClassifier.train(train_set) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to test this classifier on a single sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'Awesome eggs, I do not liked them'\n",
      "--------------\n",
      "\n",
      "Positive: 0.375\n",
      "Negative: 0.25\n"
     ]
    }
   ],
   "source": [
    "neg = 0\n",
    "pos = 0\n",
    "testsentence = \"Awesome eggs, I do not liked them\"\n",
    "words = nltk.word_tokenize(testsentence)\n",
    "for word in words:\n",
    "    classResult = classifier.classify(word_feats(word))\n",
    "    if classResult == 'neg':\n",
    "        neg = neg + 1\n",
    "    if classResult == 'pos':\n",
    "        pos = pos + 1\n",
    " \n",
    "print(\"Sentence: '{}'\\n--------------\\n\".format(testsentence))\n",
    "print('Positive: ' + str(float(pos)/len(words)))\n",
    "print('Negative: ' + str(float(neg)/len(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some data sets for sentiment analysis\n",
    "https://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "https://github.com/nltk/nltk/wiki/Sentiment-Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "Take one of these data sets and train a NaiveBayesClassifier from these data sets. You need to define a loop to read the texts from each file and get the word features from each. Make sure you concatenate the features and do not loose them along the way.\n",
    "\n",
    "At the end provide statistics on the data set: how many files per category, how many features.\n",
    "\n",
    "Divide a split over training and test data. Train the classifier using the train set and evaluate the classifier on the test set.\n",
    "\n",
    "Obtain 50 tweets and create a gold data set from these tweets. How would you create the gold data automatically?\n",
    "Test the classifier on your tweets. Provide a contigency table for it.\n",
    "\n",
    "Why would it be better to use an independent test set instead of a split over the data set into test and train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not being used\n",
    "## How can you use the panda package to read files and create a data set\n",
    "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "#from sklearn.model_selection import train_test_split # function for splitting data to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
