{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating your results \n",
    "\n",
    "\n",
    "## Background reading\n",
    "\n",
    "NLTK https://www.nltk.org/book/ch06.html\n",
    "\n",
    "* section 1 Learning to Classify Text \n",
    "* section 3 Evaluation \n",
    "* section 5 Naive Bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build your own little name classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import names\n",
    "\n",
    "def gender_features(word):\n",
    "     return {'last_letter': word[-1]}\n",
    " \n",
    "gender_features('Shrek')\n",
    "{'last_letter': 'k'}\n",
    "\n",
    "\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] \n",
    "         + [(name, 'female') for name in names.words('female.txt')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task: Make sure you know what is happening in this command! \n",
    " \n",
    "random.shuffle(names)\n",
    "featuresets = [(gender_features(n), g) for (n,g) in names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_letter': 'k'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'd'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'o'} male\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'm'} male\n",
      "{'last_letter': 'b'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'w'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'o'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'o'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'k'} male\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'd'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'd'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'm'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'd'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'u'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'o'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'x'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'm'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'g'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'o'} male\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'o'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'c'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'd'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'b'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'm'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'o'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'x'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'k'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'd'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'k'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'f'} male\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'k'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'd'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'v'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'v'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'x'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'w'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'd'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'o'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'o'} male\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'k'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'o'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'd'} male\n",
      "{'last_letter': 'h'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 's'} male\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'k'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'i'} female\n",
      "{'last_letter': 'v'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'u'} male\n",
      "{'last_letter': 'r'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'l'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'n'} male\n",
      "{'last_letter': 'y'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 't'} male\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'f'} male\n",
      "{'last_letter': 'e'} female\n",
      "{'last_letter': 'a'} female\n",
      "{'last_letter': 'd'} male\n",
      "{'last_letter': 'y'} female\n"
     ]
    }
   ],
   "source": [
    "#However, it is more insightful to get the precision, recall and f-measure scores per class out. You can do this with the nltk.metrics module:\n",
    "from nltk.metrics import precision, recall, f_measure  \n",
    "import collections \n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "for i, (test_instance, label) in enumerate(test_set):\n",
    "     refsets[label].add(i)\n",
    "     observed = classifier.classify(test_instance)\n",
    "    # print (test_instance, observed)\n",
    "     testsets[observed].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male precision: 0.6417112299465241\n",
      "male recall: 0.7017543859649122\n",
      "male F-measure: 0.6703910614525139\n",
      "female precision: 0.8370607028753994\n",
      "female recall: 0.7963525835866262\n",
      "female F-measure: 0.8161993769470405\n"
     ]
    }
   ],
   "source": [
    "print('male precision:', precision(refsets['male'], testsets['male']))\n",
    "print('male recall:', recall(refsets['male'], testsets['male']))\n",
    "print('male F-measure:', f_measure(refsets['male'], testsets['male']))\n",
    "print('female precision:', precision(refsets['female'], testsets['female']))\n",
    "print('female recall:', recall(refsets['female'], testsets['female']))\n",
    "print('female F-measure:', f_measure(refsets['female'], testsets['female']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK\n",
    "https://www.nltk.org/book/ch06.html\n",
    "3   Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import brown\n",
    "tagged_sents = list(brown.tagged_sents(categories='news'))\n",
    "random.shuffle(tagged_sents)\n",
    "size = int(len(tagged_sents) * 0.1)\n",
    "train_set, test_set = tagged_sents[size:], tagged_sents[:size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to find out what tagged_sents is. Once you know try to construct a similar data object from your own texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mrs.', 'NP'),\n",
       " ('Marr', 'NP'),\n",
       " ('also', 'RB'),\n",
       " ('has', 'HVZ'),\n",
       " ('a', 'AT'),\n",
       " ('number', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('parolees', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('``', '``'),\n",
       " ('mother', 'VB'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " ('watching', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('that', 'CS'),\n",
       " ('they', 'PPSS'),\n",
       " ('do', 'DO'),\n",
       " ('not', '*'),\n",
       " ('break', 'VB'),\n",
       " ('their', 'PP$'),\n",
       " ('parole', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('that', 'CS'),\n",
       " ('they', 'PPSS'),\n",
       " ('also', 'RB'),\n",
       " ('learn', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('readjust', 'VB'),\n",
       " ('to', 'IN'),\n",
       " ('society', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the last sentence\n",
    "tagged_sents[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to perform a more stringent evaluation, we can draw the test set from documents that are less closely related to those in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = brown.tagged_sents(categories='news')\n",
    "test_set = brown.tagged_sents(categories='fiction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d02182b27434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print('Accuracy: {:4.2f}'.format())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/classify/naivebayes.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# Count up how many times each feature value occurred, given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# the label and featurename.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mlabel_freqdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "accuracy\n",
    "\n",
    "#print('Accuracy: {:4.2f}'.format()) \n",
    "#0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_sents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-772766d2b289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnigramTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBigramTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_sents' is not defined"
     ]
    }
   ],
   "source": [
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "\n",
    "def tag_list(tagged_sents):\n",
    "     return [tag for sent in tagged_sents for (word, tag) in sent]\n",
    "def apply_tagger(tagger, corpus):\n",
    "     return [tagger.tag(nltk.tag.untag(sent)) for sent in corpus]\n",
    "gold = tag_list(brown.tagged_sents(categories='editorial'))\n",
    "test = tag_list(apply_tagger(t2, brown.tagged_sents(categories='editorial')))\n",
    "cm = nltk.ConfusionMatrix(gold, test)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARIEK's LEFTOVERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: for multiclass problems, it may be more informative to get a confusion matrix that shows you which classes often are confused with which. \n",
    "\n",
    "In Section 3.4 of chapter 6 of the NLTK book you find an example of a confusion matrix. If you are thinking of doing a multiclass classification for your final assignment, try to make such a confusion class yourself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip: The python Scikit learn package has extensive metrics options such as http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support and http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report \n",
    "\n",
    "\n",
    "IMPORTANT TO NOTE: When you report on such experiments, don't just provide p/r/f measures (quantitative evaluation) but also look at what it going wrong and try to figure out why (qualitative evaluation). The reason for performing a qualitative evaluation is that it can give you insights into what the system is doing, and give you hints as to how to correct it, and if not for yourself, this is useful to the reader of your report who can then make a better decision as to whether to use the system, build upon it etc.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "Tips & Tricks\n",
    "Have you thought about storing your (intermediate) results and models? You may want to look into the Python pickle module. This allows you to store for example a classifier but you may also want to use it to store your data somehow. You may also write tagging results to good old regular text files of course. Google your way to what works best for you. \n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "Further reading & hacking: \n",
    "If you are interested in doing a machine learning experiment for your final assignment, you can find more hints as to how to build your own feature sets in NLTK chapter 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
