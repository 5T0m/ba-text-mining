{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@TODO:\n",
    "    - what to install and import\n",
    "    - TRAIN: notebook how to build a model\n",
    "    - EVALUATE: notebook how to use your own training and test data\n",
    "    - APPLY: notebook how to apply a model to your use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 25000 training samples, 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 100 #5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 2, 2, 66, 2, 4, 2, 36, 2, 5, 25, 2, 43, 2, 2, 50, 2, 2, 9, 35, 2, 2, 5, 2, 4, 2, 2, 2, 2, 2, 2, 39, 4, 2, 2, 2, 17, 2, 38, 13, 2, 4, 2, 50, 16, 6, 2, 2, 19, 14, 22, 4, 2, 2, 2, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 2, 12, 8, 2, 8, 2, 5, 4, 2, 2, 16, 2, 66, 2, 33, 4, 2, 12, 16, 38, 2, 5, 25, 2, 51, 36, 2, 48, 25, 2, 33, 6, 22, 12, 2, 28, 77, 52, 5, 14, 2, 16, 82, 2, 8, 4, 2, 2, 2, 15, 2, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 2, 26, 2, 2, 46, 7, 4, 2, 2, 13, 2, 88, 4, 2, 15, 2, 98, 32, 2, 56, 26, 2, 6, 2, 2, 18, 4, 2, 22, 21, 2, 2, 26, 2, 5, 2, 30, 2, 18, 51, 36, 28, 2, 92, 25, 2, 4, 2, 65, 16, 38, 2, 88, 12, 16, 2, 5, 16, 2, 2, 2, 32, 15, 16, 2, 19, 2, 32]),\n",
       "       list([1, 2, 2, 2, 2, 78, 2, 5, 6, 2, 2, 2, 2, 26, 4, 2, 8, 2, 2, 14, 2, 20, 13, 2, 2, 2, 2, 5, 2, 2, 2, 21, 14, 69, 2, 8, 30, 23, 7, 4, 2, 2, 93, 4, 2, 9, 2, 2, 5, 2, 4, 2, 9, 35, 2, 4, 2, 9, 2, 2, 4, 2, 9, 4, 2, 2, 19, 4, 2, 5, 89, 29, 2, 46, 37, 4, 2, 9, 45, 43, 38, 2, 2, 2, 4, 2, 26, 2, 5, 2, 11, 2, 2, 4, 2, 9, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2, 2, 15, 2, 2, 68, 2, 2, 15, 2, 2, 2, 98, 5, 4, 2, 9, 43, 2, 2, 15, 2, 2, 5, 2, 2, 11, 2, 2, 2, 50, 9, 2, 2, 2, 5, 2, 2, 2, 2, 5, 4, 2, 2, 2, 2, 18, 2, 32, 2, 2, 14, 9, 6, 2, 78, 22, 2, 64, 2, 9, 8, 2, 2, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 2, 2, 33, 89, 78, 2, 16, 2, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 2, 2, 7, 4, 2, 54, 61, 2, 13, 71, 2, 14, 22, 2, 4, 2, 2, 12, 16, 2, 33, 75, 43, 2, 2, 4, 86, 2, 35, 2, 19, 2, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 2, 7, 4, 58, 2, 2, 11, 4, 2, 43, 2, 2, 8, 2, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 2, 2, 2, 36, 69, 2, 2, 8, 2, 14, 2, 2, 18, 6, 22, 12, 2, 28, 2, 40, 6, 87, 2, 23, 2, 21, 23, 22, 12, 2, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 2, 23, 2, 2, 2, 2, 13, 2, 79, 2, 89, 2, 14, 9, 8, 2, 2, 2, 35, 2, 6, 2, 7, 2, 2]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 2, 2, 2, 9, 6, 2, 2, 2, 45, 2, 84, 2, 2, 21, 4, 2, 84, 2, 2, 2, 2, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 2, 8, 2, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 2, 2, 2, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 2, 2, 2, 29, 2, 11, 2, 2, 45, 40, 29, 2, 2, 11, 6, 2, 2, 7, 2, 89, 2, 70, 29, 2, 4, 64, 2, 11, 4, 2, 26, 2, 4, 2, 2, 2, 5, 27, 2, 2, 2, 2, 2, 47, 84, 37, 2, 2, 14, 2, 10, 10, 61, 2, 2, 10, 10, 2, 2, 2, 34, 2, 2, 4, 65, 2, 4, 2, 7, 2, 5, 6, 2, 2, 2, 2, 2, 2, 7, 2, 4, 2, 2, 2, 2, 2, 5, 2, 18, 4, 2, 2, 2, 11, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 4, 59, 2, 4, 2, 2]),\n",
       "       list([1, 2, 2, 69, 72, 2, 13, 2, 2, 8, 12, 2, 23, 5, 16, 2, 2, 54, 2, 11, 2, 2, 45, 58, 2, 13, 2, 12, 16, 43, 23, 2, 5, 62, 30, 2, 2, 11, 2, 51, 2, 32, 61, 2, 71, 66, 2, 12, 2, 75, 2, 2, 8, 4, 2, 37, 69, 2, 2, 75, 2, 44, 2, 2, 5, 69, 2, 2, 2, 50, 2, 2, 23, 4, 2, 13, 2, 40, 5, 2, 4, 2, 16, 2, 13, 2, 40, 2, 2, 2, 2, 11, 2, 2, 25, 70, 2, 4, 2, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 2, 5, 2, 25, 8, 2, 12, 2, 5, 2, 12, 2, 2, 2, 12, 6, 52, 58, 2, 92, 2, 2, 12, 39, 14, 2, 8, 15, 2, 5, 2, 12, 38, 84, 80, 2, 12, 9, 23]),\n",
       "       list([1, 17, 6, 2, 2, 7, 4, 2, 22, 45, 2, 8, 2, 14, 2, 4, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 39, 14, 2, 4, 2, 9, 2, 50, 2, 12, 47, 4, 2, 5, 2, 7, 38, 2, 2, 2, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 2, 42, 97, 90, 35, 2, 2, 29, 2, 27, 2, 8, 97, 12, 2, 21, 2, 2, 9, 6, 66, 78, 2, 4, 2, 2, 5, 2, 2, 2, 2, 6, 2, 8, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 8, 2, 2, 2, 21, 60, 27, 2, 9, 43, 2, 2, 2, 10, 10, 12, 2, 40, 4, 2, 20, 12, 16, 5, 2, 2, 72, 7, 51, 6, 2, 22, 4, 2, 2, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review---\n",
      "[1, 2, 2, 2, 2, 78, 2, 5, 6, 2, 2, 2, 2, 26, 4, 2, 8, 2, 2, 14, 2, 20, 13, 2, 2, 2, 2, 5, 2, 2, 2, 21, 14, 69, 2, 8, 30, 23, 7, 4, 2, 2, 93, 4, 2, 9, 2, 2, 5, 2, 4, 2, 9, 35, 2, 4, 2, 9, 2, 2, 4, 2, 9, 4, 2, 2, 19, 4, 2, 5, 89, 29, 2, 46, 37, 4, 2, 9, 45, 43, 38, 2, 2, 2, 4, 2, 26, 2, 5, 2, 11, 2, 2, 4, 2, 9, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2, 2, 15, 2, 2, 68, 2, 2, 15, 2, 2, 2, 98, 5, 4, 2, 9, 43, 2, 2, 15, 2, 2, 5, 2, 2, 11, 2, 2, 2, 50, 9, 2, 2, 2, 5, 2, 2, 2, 2, 5, 4, 2, 2, 2, 2, 18, 2, 32, 2, 2, 14, 9, 6, 2, 78, 22, 2, 64, 2, 9, 8, 2, 2, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 2, 2, 33, 89, 78, 2, 16, 2, 95]\n",
      "---label---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print('---review---')\n",
    "print(X_train[1])\n",
    "print('---label---')\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review with words---\n",
      "['the', 'and', 'and', 'and', 'to', 'and', 'and', 'this', 'as', 'and', 'and', 'br', 'and', 'and', 'and', 'and', 'has', 'of', 'and', 'and', 'and', 'to', 'and', 'of', 'and', 'this', 'and', 'and', 'and', 'and', 'and', 'to', 'and', 'he', 'is', 'and', 'and', 'movie', 'and', 'like', 'and', 'and', 'and', 'and', 'to', 'and', 'in', 'and', 'for', 'from', 'and', 'and', 'because', 'very', 'and', 'it', 'is', 'and', 'and', 'really', 'and', 'is', 'and', 'too', 'and', 'and', 'of', 'and', 'br', 'of', 'and', 'and', 'and', 'really', 'there', 'will', 'and', 'and', 'is', 'and', 'this', 'make', 'and', 'and', 'was', 'and', 'of', 'and', 'br', 'of', 'you', 'to', \"don't\", 'and', 'than', 'and', 'she', 'to', 'was', 'and', 'that', 'and', 'and', 'movies', 'get', 'are', 'and', 'br', 'and', 'and', 'just', 'its', 'because', 'and', 'br', 'of', 'and', 'to', 'and', 'people', 'time', 'very', 'and']\n",
      "---label---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print('---review with words---')\n",
    "print([id2word.get(i, ' ') for i in X_train[6]])\n",
    "print('---label---')\n",
    "print(y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 2697\n"
     ]
    }
   ],
   "source": [
    "print('Maximum review length: {}'.format(\n",
    "len(max((X_train + X_test), key=len))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum review length: 14\n"
     ]
    }
   ],
   "source": [
    "print('Minimum review length: {}'.format(\n",
    "len(min((X_test + X_test), key=len))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           3200      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 56,501\n",
      "Trainable params: 56,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "embedding_size=32\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24936 samples, validate on 64 samples\n",
      "Epoch 1/1\n",
      "24936/24936 [==============================] - 232s 9ms/step - loss: 0.6403 - acc: 0.6191 - val_loss: 0.6254 - val_acc: 0.7031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10a51b278>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 1 #3\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6904\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "length of the input must be the same as the length of the training data, max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759 0.89337759\n",
      " 0.89337759 0.89337759], Predicted=[1]\n"
     ]
    }
   ],
   "source": [
    "Xnew = np.array([[0.89337759] * 500])\n",
    "# make a prediction\n",
    "ynew = model.predict_classes(Xnew)\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use model.save(filepath) to save a Keras model into a single HDF5 file which will contain:\n",
    "\n",
    "the architecture of the model, allowing to re-create the model\n",
    "the weights of the model\n",
    "the training configuration (loss, optimizer)\n",
    "the state of the optimizer, allowing to resume training exactly where you left off.\n",
    "You can then use keras.models.load_model(filepath) to reinstantiate your model. load_model will also take care of compiling the model using the saved training configuration (unless the model was never compiled in the first place)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
