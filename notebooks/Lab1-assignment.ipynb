{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1-Assignment\n",
    "\n",
    "Due: TODO\n",
    "\n",
    "Please name your ipython notebook with the following naming convention: TODO\n",
    "\n",
    "Please submit your assignment using TODO\n",
    "\n",
    "If you have questions about this topic, TODO\n",
    "\n",
    "This notebook describes the assignment for Lab 1 of the text mining course. \n",
    "\n",
    "We assume you have worked through the following notebooks:\n",
    "* **Lab1-introduction**\n",
    "* **Lab1-introduction-to-NLTK**\n",
    "* **Lab1-introduction-to-Spacy** \n",
    "\n",
    "In these notebooks, we've shown you how to work with NLTK and spaCy to perform NLP tasks on unstructured data.\n",
    "In this assignment, you will process an English text with both NLTK and spaCy and discuss the similarities and differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip: how to read a file from disk\n",
    "Let's open the file **Lab1-apple-samsung-example.txt** from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = Path().resolve() # this should provide you with the folder in which this notebook is placed\n",
    "path_to_file = os.path.join(cur_dir, 'Lab1-apple-samsung-example.txt') # this should provide you with the absolute path to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters 1139\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as infile:\n",
    "    text = infile.read()\n",
    "\n",
    "print('number of characters', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [points: TODO] Exercise 1: finding a file\n",
    "create a file with an English text of around 500 words. Make sure the text is in UTF-8 encoding and it includes longer sentences with sufficient entities. You can start with any text. \n",
    "Please keep adapting the file manually to make sure you can show the similarities and differences between NLTK and SpaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: TODO] Exercise 2: NLTK\n",
    "* Use NLTK to perform the following NLP tasks on your file:\n",
    "    1. [points: TODO] **Sentence splitting**: *nltk.tokenize.sent_tokenize*\n",
    "    2. [points: TODO]**Tokenization**: *nltk.word_tokenize*\n",
    "    * [points: TODO]**Part-of-speech (POS) tagging**: *nltk.pos_tag* \n",
    "    * [points: TODO]**Stop words recognition** \n",
    "    * [points: TODO]**Stemming and lemmatization**\n",
    "         * *nltk.stem.porter.PorterStemmer*\n",
    "         * *nltk.stem.snowball.SnowballStemmer*\n",
    "         * *nltk.stem.wordnet.WordNetLemmatizer*\n",
    "    * [points: TODO]**Constituency/dependency parsing** *nltk.RegexpParser*\n",
    "    * [points: TODO]**Named Entity Recognition (NER)** *nltk.chunk.ne_chunk*\n",
    "    \n",
    "    \n",
    "In addition:\n",
    "8. [points: TODO]count the number of sentences\n",
    "9. [points: TODO]count the words\n",
    "10. [points: TODO]Augment the RegexpParser so that it also detects Named Entity Phrases (NEP) and apply this on a relevant selected sentence.\n",
    "11. [points: TODO] Visualise the tree structure of one sentence and include the image in your report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: TODO] Exercise 3: spaCy\n",
    "1. [points: TODO] Use Spacy to process the same text as you just processed with NLTK for the following NLP tasks.\n",
    "        \n",
    "In addition:   \n",
    "2. [points: TODO] Visualise the dependecy structure of the sentence through spacy and save it a file, which should be included in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Comparison NLTK and spaCy\n",
    "In this exercise, you are going to perform the output from NLTK and spaCy. We focus on the tasks that we've been using in the exercise:\n",
    "* [points: TODO] **Sentence splitting** \n",
    "* [points: TODO] **Tokenization**:\n",
    "* [points: TODO] **Part-of-speech (POS) tagging**:\n",
    "* [points: TODO] **Stop words recognition** \n",
    "* [points: TODO] **Stemming and lemmatization**\n",
    "* [points: TODO] **Constituency/dependency parsing**: note: you can compare images that vizualize the tree structure\n",
    "* [points: TODO] **Named Entity Recognition (NER)**\n",
    "\n",
    "The goal of this exercise is to show where NLTK and spaCy **differ**! We encourage you to include sentences that show where NLTK and spaCy excel and where they differ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit your assignment as a Jupyter notebook and as a PDF file via Canvas. You can save the notebook as a PDF file through the File/Download as menu.\n",
    "\n",
    "Please note that submissions should contain a title, your group number, your names.\n",
    "\n",
    "We will strive to give you feedback before the next Lab session."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
