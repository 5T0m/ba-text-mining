{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab5 - Assignment 5 about extraction of properties\n",
    "This notebook describes the LAB-5 assignment of the Text Mining course. It is about Property Extraction.\n",
    "\n",
    "**Due**: 17 Mar at 23:59\n",
    "\n",
    "**How to submit**: Please submit your assignment using Canvas (see *Assignments* -> *Lab Session Property Extraction*). Convert your notebook to PDF (in JupyterLab, this can be done by clicking on *File* in the menu bar, select *Export Notebook As*, then select *Export Notebook to PDF*)\n",
    "\n",
    "**Points**: each exercise is suffixed with the number of points you can obtain for the exercise.\n",
    "\n",
    "**Questions**: If you have questions about this topic, you can either ask them during the lab session or email:\n",
    "* Filip Ilievski (f.ilievski@vu.nl)\n",
    "* Robert Kajnak: (r.kajnakmisca@student.vu.nl)\n",
    "* Karen Goes: (k.w.m.goes@student.vu.nl)\n",
    "\n",
    "**Assignment goals**:\n",
    "* Get insight into the challenges of entity property extraction.\n",
    "* Learn how to build a transparent property extraction method based on patterns.\n",
    "* Get insight into the pros and cons of pattern-based property extraction.\n",
    "* Be able to evaluate property extractors.\n",
    "\n",
    "In this assignment, the main focus lies on creating your own pattern-based property extractors. You are then going to run them on Wikipedia texts, evaluate them against gold values, and reflect on their relative performance.\n",
    "\n",
    " We recommend that you go through the notebooks in the following order:\n",
    "* *Read the assignment (see below)*\n",
    "* *Lab5-Property-extraction.ipynb*\n",
    "* *Answer the questions of the assignment (see below) using the provided notebooks and submit*\n",
    "\n",
    "**Good luck & have fun!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extracting birth year of people (12 points)\n",
    "\n",
    "\n",
    "**Exercise 1a** Write code that extracts the birth year of a person by using regular expressions. (4 points)\n",
    "\n",
    "Hint: in the explanation notebook, we had an example about extracting founding years of organizations. You can use much of this code here, but make sure you make the right adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_birth_year_regex():\n",
    "    # Extract the birth year of a person with regular expressions\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1b** Write code that extracts the birth year of a person by using dependencies. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_birth_year_dep():\n",
    "    # Extract the birth year of a person by using dependency information\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1c** Write or find two sentences on which you expect that the extractors *WILL* work. Run your extractors on this text and print the results. Make sure that the result is as expected. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1d** Write or find two sentences on which you expect that the extractors *WILL NOT* work. Run your extractors on this text and print the results. Make sure that the result is as expected. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extracting device manufacturers (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2a** Write code that extracts the manufacturer of a device by using dependencies. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_manufacturer_dep(text):\n",
    "    # Extract the manufacturer of a device with dependencies\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2b** Write code that extracts the manufacturer of a device by using regular expressions. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_manufacturer_regex(text):\n",
    "    # Extract the manufacturer of a device by using regular expressions\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2c** Write or find two sentences on which you expect that the extractors *WILL* work. Run your extractors on this text and print the results. Make sure that the result is as expected. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2d** Write or find two sentences on which you expect that the extractors *WILL NOT* work. Run your extractors on this text and print the results. Make sure that the result is as expected. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Running and evaluating extractors on Wikipedia (8 points)\n",
    "\n",
    "We will run our extractors on 50 documents about people and 50 documents about devices. We provide code to load the lists of entities and the gold values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"birthyears.json\", 'rb') as f:\n",
    "    gold_birthyears=json.load(f)\n",
    "    wiki_people=list(gold_birthyears.keys())\n",
    "    \n",
    "with open(\"manufacturers.json\", 'rb') as f:\n",
    "    gold_manufacturers=json.load(f)\n",
    "    wiki_devices=list(gold_countries.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lists `wiki_people` and `wiki_devices` contain the names of 50 people and 50 devices, respectively.\n",
    "\n",
    "The dictionaries `gold_birthyears` and `gold_manufacturers` contain gold values for each of these entities.\n",
    "\n",
    "We provide a function that evaluates your extracted property values against known (\"gold\") property values. The function returns the evaluation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_property(sys_property_data, gold_property_data):\n",
    "    \"\"\"\n",
    "    Compare the system output to the gold data to compute precision, recall, and F1-score. \n",
    "    \"\"\"\n",
    "    tp=0\n",
    "    fp=0\n",
    "    fn=0\n",
    "    for entity, gold_value in gold_property_data.items():\n",
    "        if entity in sys_property_data: \n",
    "            system_value=sys_property_data[entity]\n",
    "            if system_value==gold_value:\n",
    "                tp+=1\n",
    "            else:\n",
    "                fp+=1\n",
    "                fn+=1\n",
    "        else:\n",
    "            fn+=1\n",
    "        \n",
    "    if tp+fp>0:\n",
    "        precision=tp/(tp+fp)\n",
    "    else:\n",
    "        precision=0\n",
    "    if tp+fn>0:\n",
    "        recall=tp/(tp+fn)\n",
    "    else:\n",
    "        recall=0\n",
    "    if precision+recall>0:\n",
    "        f1=2*precision*recall/(precision+recall)\n",
    "    else:\n",
    "        f1=0\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have stored the gold values for both properties in our dictionaries `gold_birthyears` and `gold_manufacturers`, and written the evaluation function, we need to obtain the system output as well and then perform evaluation.\n",
    "\n",
    "For this purpose, we will run our extractors on texts about the same 50 people and 50 devices from Wikipedia. As in the explanation notebook, we will use the `Wikipedia` library for this purpose.\n",
    "\n",
    "In exercises 3a and 3b, we will run all our four processing functions and store the results in four different dictionaries. \n",
    "Then, in exercise 3c, we will run the evaluation function four times to compute precision, recall, and F1-score for all four functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3a** Run your two extractors about birth years of people (from exercise 1a and 1b) on all 50 documents about people. Save the extracted values in two different dictionaries: `birthyear_regex` and `birthyear_dep`. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3b** Run your extractors about manufacturers of devices (from exercise 2a and 2b) on all 50 documents about devices. Save the extracted values in two lists: `manufacturers_regex` and `manufacturers_dep`. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3c** Run the evaluation function `evaluate_property` to compute the performance for each of your four functions. Print the precision, recall, and F1-scores. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Reflection (6 points)\n",
    "\n",
    "For each entity, we will now compare the two methods to extract properties in terms of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4a** Comparing the precision between the methods based on regular expressions and on syntax dependencies:\n",
    "* Which method yields lower precision?\n",
    "* Why do you think this is the case?\n",
    "\n",
    "(3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4b** Let's compare the recall for both properties. \n",
    "* Which method yields lower recall?\n",
    "* Why do you think this is the case?\n",
    "\n",
    "(3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
